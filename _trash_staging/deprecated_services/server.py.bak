"""
LawyerFactory Canonical API Server - Consolidated Backend
Unified Flask-SocketIO server with comprehensive phase orchestration, evidence management,
and real-time communication for the legal document automation system.

This is the single source of truth for all LawyerFactory backend functionality.

Key Features:
- Unified phase orchestration (A01-A03, B01-B02, C01-C02)
- Real-time Socket.IO communication
- Evidence table management with PRIMARY/SECONDARY classification
- LLM provider integration with fallback
- Unified storage API integration
- Research bot with Tavily integration
- Claims matrix generation
- Skeletal outline generation
- Drafting validation
- Background task processing
- Comprehensive error handling and logging

Consolidated from:
- apps/api/server.py (comprehensive server)
- apps/api/simple_server.py (simplified server)
- src/lawyerfactory/phases/phaseB01_review/ui/api_app_main.py (UI-focused server)
- apps/api/routes/evidence_flask.py (Flask evidence API)
- apps/api/routes/research_flask.py (Flask research API)
"""

import eventlet
import os
from pathlib import Path
import sys
import argparse
import logging
import asyncio
import json
import time
import uuid
from typing import Any, Dict, List, Optional

# Monkey patch must be first for eventlet
eventlet.monkey_patch()

# Add src to path for lawyerfactory imports
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "src"))
import argparse
import logging

# Import canonical evidence API
from canonical_evidence_api import evidence_bp, initialize_canonical_evidence_api

from flask import Flask, jsonify, render_template, request, send_file
from flask_cors import CORS
from flask_socketio import SocketIO, emit, join_room, leave_room
from werkzeug.utils import secure_filename

"""
LawyerFactory API Server
Flask-based REST API with Socket.IO for real-time communication
"""

import asyncio
import json
import logging
import os
from pathlib import Path
import sys
import time
from typing import Any, Dict, List, Optional

# ============================================================================
# CONFIGURATION & LOGGING
# ============================================================================

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Create Flask app with enhanced configuration
app = Flask(__name__)
app.config["SECRET_KEY"] = os.environ.get("SECRET_KEY", "lawyerfactory-canonical-secret-key")
app.config["UPLOAD_FOLDER"] = "uploads"
app.config["MAX_CONTENT_LENGTH"] = 50 * 1024 * 1024  # 50MB max file size
app.config["PERMANENT_SESSION_LIFETIME"] = 3600  # 1 hour

# Enable CORS with enhanced configuration
CORS(app, origins=["*"], supports_credentials=True)

# Create Socket.IO server with eventlet for async support
socketio = SocketIO(
    app,
    cors_allowed_origins="*",
    async_mode="eventlet",
    logger=True,
    engineio_logger=True
)
    # Add src to path for imports
src_path = Path(__file__).parent.parent.parent / "src"
    if str(src_path) not in sys.path:
        sys.path.insert(0, str(src_path))

    # Import with fallbacks for missing dependencies
    try:
        from lawyerfactory.agents.research.court_authority_helper import (
            CourtAuthorityHelper,
            JurisdictionContext,
            LegalQuestionType,
        )

        COURT_AUTHORITY_AVAILABLE = True
    except ImportError:
        CourtAuthorityHelper = None
        COURT_AUTHORITY_AVAILABLE = False
        logger.warning("CourtAuthorityHelper not available")

    try:
        from lawyerfactory.agents.research.research import ResearchBot

        RESEARCH_BOT_AVAILABLE = True
    except ImportError:
        ResearchBot = None
        RESEARCH_BOT_AVAILABLE = False
        logger.warning("ResearchBot not available")

    try:
        from lawyerfactory.evidence.table import EnhancedEvidenceTable

        EVIDENCE_TABLE_AVAILABLE = True

# Import LawyerFactory components (optional)
LAWYERFACTORY_AVAILABLE = False
    try:
        from lawyerfactory.storage.unified_storage import UnifiedStorage
        # Create mock evidence data for demonstration
        evidence_list = [
            {
                "evidence_id": "evidence_001",
                "object_id": "obj_12345",
                "filename": "contract.pdf",
                "description": "Employment contract between plaintiff and defendant",
                "evidence_source": "primary",
                "status": "analyzed",
                "file_size": 245760,
                "upload_date": "2024-01-15T10:30:00Z",
                "phase": "phaseA01_intake",
                "tags": "contract, employment, terms",
                "facts": ["Contract executed on 2023-06-01", "Annual salary $85,000"],
                "research_query": "employment contract validity",
                "research_confidence": 0.85,
            },
            {
                "evidence_id": "evidence_002",
                "object_id": "obj_12346",
                "filename": "termination_letter.pdf",
                "description": "Termination notice from HR department",
                "evidence_source": "primary",
                "status": "analyzed",
                "file_size": 189440,
                "upload_date": "2024-01-15T11:15:00Z",
                "phase": "phaseA01_intake",
                "tags": "termination, HR, notice",
                "facts": ["Employment terminated on 2023-12-15", "Reason: performance issues"],
                "research_query": "wrongful termination analysis",
                "research_confidence": 0.92,
            },
            {
                "evidence_id": "evidence_003",
                "object_id": "obj_12347",
                "filename": "case_law_research.pdf",
                "description": "Relevant case law on wrongful termination",
                "evidence_source": "secondary",
                "status": "analyzed",
                "file_size": 567890,
                "upload_date": "2024-01-16T09:45:00Z",
                "phase": "phaseA02_research",
                "tags": "case law, precedent, wrongful termination",
                "facts": ["Similar case: Smith v. ABC Corp (2022)", "Court found for plaintiff"],
                "research_query": "wrongful termination precedents",
                "research_confidence": 0.78,
            }
        ]

        return jsonify({
            "success": True,
            "evidence": evidence_list,
            "total": len(evidence_list),
            "primary_count": len([e for e in evidence_list if e["evidence_source"] == "primary"]),
            "secondary_count": len([e for e in evidence_list if e["evidence_source"] == "secondary"]),
        })
    except Exception as e:
        logger.error(f"Failed to get evidence table: {e}")
        return jsonify({"error": str(e)}), 500


@app.route("/api/evidence", methods=["POST"])
def add_enhanced_evidence_entry():
    """Add new evidence entry with enhanced validation"""
    try:
        data = request.get_json()

        # Validate required fields
        required_fields = ["source_document", "content", "evidence_source"]
        for field in required_fields:
            if not data.get(field):
                return jsonify({"error": f"Field '{field}' is required"}), 400

        # Create evidence entry
        evidence_id = f"evidence_{int(time.time())}"

        evidence_entry = {
            "evidence_id": evidence_id,
            "object_id": data.get("object_id", f"obj_{int(time.time())}"),
            "source_document": data.get("source_document"),
            "page_section": data.get("page_section", ""),
            "content": data.get("content"),
            "evidence_type": data.get("evidence_type", "documentary"),
            "evidence_source": data.get("evidence_source"),  # primary or secondary
            "relevance_score": float(data.get("relevance_score", 0.0)),
            "relevance_level": data.get("relevance_level", "unknown"),
            "bluebook_citation": data.get("bluebook_citation", ""),
            "privilege_marker": data.get("privilege_marker", "none"),
            "extracted_date": data.get("extracted_date"),
            "witness_name": data.get("witness_name"),
            "key_terms": data.get("key_terms", []),
            "notes": data.get("notes", ""),
            "research_query": data.get("research_query"),
            "research_confidence": float(data.get("research_confidence", 0.0)),
            "created_by": data.get("created_by", "user"),
            "created_at": time.time(),
            "status": "stored",
            "phase": data.get("phase", "phaseA01_intake"),
        }

        # In production, save to evidence table
        # evidence_table.add_evidence(evidence_entry)

        # Emit real-time update
        socketio.emit("evidence_added", {
            "evidence": evidence_entry,
            "timestamp": time.time()
        })

        return jsonify({
            "success": True,
            "evidence_id": evidence_id,
            "message": "Evidence entry added successfully",
            "evidence": evidence_entry
        })

    except Exception as e:
        logger.error(f"Failed to add evidence entry: {e}")
        return jsonify({"error": str(e)}), 400


@app.route("/api/evidence/<evidence_id>/download", methods=["GET"])
def download_enhanced_evidence(evidence_id):
    """Download evidence file with enhanced error handling"""
    try:
        # In production, retrieve from unified storage
        # if unified_storage:
        #     result = await unified_storage.get_evidence(evidence_id)
        #     return send_file(BytesIO(result["content"]), ...)

        # Mock download for demonstration
        mock_content = f"Mock content for evidence {evidence_id}"
        from io import BytesIO
        return send_file(
            BytesIO(mock_content.encode('utf-8')),
            mimetype='text/plain',
            as_attachment=True,
            download_name=f"evidence_{evidence_id}.txt"
        )
    except Exception as e:
        logger.error(f"Failed to download evidence {evidence_id}: {e}")
        return jsonify({"error": str(e)}), 500


@app.route("/api/research/execute", methods=["POST"])
def execute_enhanced_research():
    """Execute research from PRIMARY evidence with enhanced error handling"""
    try:
        data = request.get_json()

        case_id = data.get("case_id")
        evidence_id = data.get("evidence_id")
        keywords = data.get("keywords")
        max_results = data.get("max_results", 5)

        if not case_id:
            return jsonify({"error": "case_id is required"}), 400

        # Generate research ID
        research_id = f"research_{int(time.time())}"

        # Emit research started event
        socketio.emit('research_started', {
            'research_id': research_id,
            'case_id': case_id,
            'evidence_id': evidence_id,
            'keywords': keywords or ["auto-extracted"],
            'status': 'processing',
            'timestamp': time.time()
        })

        # Mock research results
        research_result = {
            'research_id': research_id,
            'case_id': case_id,
            'evidence_id': evidence_id,
            'total_sources': 3,
            'secondary_evidence_ids': [f"evidence_{int(time.time()) + i}" for i in range(3)],
            'confidence_score': 0.85,
            'sources': [
                {
                    'title': 'Smith v. ABC Corp Employment Case',
                    'citation': '2022 WL 123456 (Cal. Super. Ct.)',
                    'relevance_score': 0.92,
                    'summary': 'Similar wrongful termination case with favorable outcome for plaintiff.'
                },
                {
                    'title': 'California Labor Code § 2922',
                    'citation': 'Cal. Lab. Code § 2922',
                    'relevance_score': 0.88,
                    'summary': 'Employment at will presumption in California.'
                },
                {
                    'title': 'Employment Law Quarterly Review',
                    'citation': '45 Emp. L.Q. 123 (2023)',
                    'relevance_score': 0.76,
                    'summary': 'Recent developments in wrongful termination jurisprudence.'
                }
            ]
        }

        # Emit research completed event
        socketio.emit('research_completed', {
            'research_id': research_id,
            'case_id': case_id,
            'evidence_id': evidence_id,
            'status': 'completed',
            'total_sources': research_result['total_sources'],
            'secondary_evidence_ids': research_result['secondary_evidence_ids'],
            'confidence_score': research_result['confidence_score'],
            'timestamp': time.time()
        })

        return jsonify({
            "research_id": research_id,
            "status": "completed",
            "result": research_result,
            "message": f"Research completed with {len(research_result['secondary_evidence_ids'])} SECONDARY evidence entries"
        })

    except Exception as e:
        logger.error(f"Research execution failed: {e}")
        return jsonify({"error": str(e)}), 500

# Disable Eventlet's green DNS to prevent DNS resolution timeouts
os.environ["EVENTLET_NO_GREENDNS"] = "yes"

# ============================================================================
# GLOBAL STATE & LLM CONFIGURATION
# ============================================================================

# LLM Configuration (loaded from environment or user settings)
llm_config = {
    "provider": os.getenv("LLM_PROVIDER", "openai"),
    "model": os.getenv("LLM_MODEL", "gpt-5-nano"),
    "api_key": os.getenv("OPENAI_API_KEY") or os.getenv("ANTHROPIC_API_KEY") or os.getenv("GROQ_API_KEY"),
    "temperature": float(os.getenv("LLM_TEMPERATURE", "0.1")),
    "max_tokens": int(os.getenv("LLM_MAX_TOKENS", "200000")),
}

# Global storage for workflow states (temporary - in production use database)
research_status_store = {}
research_results_store = {}
outline_status_store = {}
outline_results_store = {}

# ============================================================================
# ENHANCED EVIDENCE API ROUTES
# ============================================================================

@app.route("/api/evidence", methods=["GET"])
def get_enhanced_evidence_table():
    """Get complete evidence table data with enhanced formatting"""
    try:
        # Create mock evidence data for demonstration
        evidence_list = [
            {
                "evidence_id": "evidence_001",
                "object_id": "obj_12345",
                "filename": "contract.pdf",
                "description": "Employment contract between plaintiff and defendant",
                "evidence_source": "primary",
                "status": "analyzed",
                "file_size": 245760,
                "upload_date": "2024-01-15T10:30:00Z",
                "phase": "phaseA01_intake",
                "tags": "contract, employment, terms",
                "facts": ["Contract executed on 2023-06-01", "Annual salary $85,000"],
                "research_query": "employment contract validity",
                "research_confidence": 0.85,
            },
            {
                "evidence_id": "evidence_002",
                "object_id": "obj_12346",
                "filename": "termination_letter.pdf",
                "description": "Termination notice from HR department",
                "evidence_source": "primary",
                "status": "analyzed",
                "file_size": 189440,
                "upload_date": "2024-01-15T11:15:00Z",
                "phase": "phaseA01_intake",
                "tags": "termination, HR, notice",
                "facts": ["Employment terminated on 2023-12-15", "Reason: performance issues"],
                "research_query": "wrongful termination analysis",
                "research_confidence": 0.92,
            },
            {
                "evidence_id": "evidence_003",
                "object_id": "obj_12347",
                "filename": "case_law_research.pdf",
                "description": "Relevant case law on wrongful termination",
                "evidence_source": "secondary",
                "status": "analyzed",
                "file_size": 567890,
                "upload_date": "2024-01-16T09:45:00Z",
                "phase": "phaseA02_research",
                "tags": "case law, precedent, wrongful termination",
                "facts": ["Similar case: Smith v. ABC Corp (2022)", "Court found for plaintiff"],
                "research_query": "wrongful termination precedents",
                "research_confidence": 0.78,
            }
        ]

        return jsonify({
            "success": True,
            "evidence": evidence_list,
            "total": len(evidence_list),
            "primary_count": len([e for e in evidence_list if e["evidence_source"] == "primary"]),
            "secondary_count": len([e for e in evidence_list if e["evidence_source"] == "secondary"]),
        })
    except Exception as e:
        logger.error(f"Failed to get evidence table: {e}")
        return jsonify({"error": str(e)}), 500


@app.route("/api/evidence", methods=["POST"])
def add_enhanced_evidence_entry():
    """Add new evidence entry with enhanced validation"""
    try:
        data = request.get_json()

        # Validate required fields
        required_fields = ["source_document", "content", "evidence_source"]
        for field in required_fields:
            if not data.get(field):
                return jsonify({"error": f"Field '{field}' is required"}), 400

        # Create evidence entry
        evidence_id = f"evidence_{int(time.time())}"

        evidence_entry = {
            "evidence_id": evidence_id,
            "object_id": data.get("object_id", f"obj_{int(time.time())}"),
            "source_document": data.get("source_document"),
            "page_section": data.get("page_section", ""),
            "content": data.get("content"),
            "evidence_type": data.get("evidence_type", "documentary"),
            "evidence_source": data.get("evidence_source"),  # primary or secondary
            "relevance_score": float(data.get("relevance_score", 0.0)),
            "relevance_level": data.get("relevance_level", "unknown"),
            "bluebook_citation": data.get("bluebook_citation", ""),
            "privilege_marker": data.get("privilege_marker", "none"),
            "extracted_date": data.get("extracted_date"),
            "witness_name": data.get("witness_name"),
            "key_terms": data.get("key_terms", []),
            "notes": data.get("notes", ""),
            "research_query": data.get("research_query"),
            "research_confidence": float(data.get("research_confidence", 0.0)),
            "created_by": data.get("created_by", "user"),
            "created_at": time.time(),
            "status": "stored",
            "phase": data.get("phase", "phaseA01_intake"),
        }

        # In production, save to evidence table
        # evidence_table.add_evidence(evidence_entry)

        # Emit real-time update
        socketio.emit("evidence_added", {
            "evidence": evidence_entry,
            "timestamp": time.time()
        })

        return jsonify({
            "success": True,
            "evidence_id": evidence_id,
            "message": "Evidence entry added successfully",
            "evidence": evidence_entry
        })

    except Exception as e:
        logger.error(f"Failed to add evidence entry: {e}")
        return jsonify({"error": str(e)}), 400


@app.route("/api/evidence/<evidence_id>/download", methods=["GET"])
def download_enhanced_evidence(evidence_id):
    """Download evidence file with enhanced error handling"""
    try:
        # In production, retrieve from unified storage
        # if unified_storage:
        #     result = await unified_storage.get_evidence(evidence_id)
        #     return send_file(BytesIO(result["content"]), ...)

        # Mock download for demonstration
        mock_content = f"Mock content for evidence {evidence_id}"
        from io import BytesIO
        return send_file(
            BytesIO(mock_content.encode('utf-8')),
            mimetype='text/plain',
            as_attachment=True,
            download_name=f"evidence_{evidence_id}.txt"
        )
    except Exception as e:
        logger.error(f"Failed to download evidence {evidence_id}: {e}")
        return jsonify({"error": str(e)}), 500


@app.route("/api/research/execute", methods=["POST"])
def execute_enhanced_research():
    """Execute research from PRIMARY evidence with enhanced error handling"""
    try:
        data = request.get_json()

        case_id = data.get("case_id")
        evidence_id = data.get("evidence_id")
        keywords = data.get("keywords")
        max_results = data.get("max_results", 5)

        if not case_id:
            return jsonify({"error": "case_id is required"}), 400

        # Generate research ID
        research_id = f"research_{int(time.time())}"

        # Emit research started event
        socketio.emit('research_started', {
            'research_id': research_id,
            'case_id': case_id,
            'evidence_id': evidence_id,
            'keywords': keywords or ["auto-extracted"],
            'status': 'processing',
            'timestamp': time.time()
        })

        # Mock research results
        research_result = {
            'research_id': research_id,
            'case_id': case_id,
            'evidence_id': evidence_id,
            'total_sources': 3,
            'secondary_evidence_ids': [f"evidence_{int(time.time()) + i}" for i in range(3)],
            'confidence_score': 0.85,
            'sources': [
                {
                    'title': 'Smith v. ABC Corp Employment Case',
                    'citation': '2022 WL 123456 (Cal. Super. Ct.)',
                    'relevance_score': 0.92,
                    'summary': 'Similar wrongful termination case with favorable outcome for plaintiff.'
                },
                {
                    'title': 'California Labor Code § 2922',
                    'citation': 'Cal. Lab. Code § 2922',
                    'relevance_score': 0.88,
                    'summary': 'Employment at will presumption in California.'
                },
                {
                    'title': 'Employment Law Quarterly Review',
                    'citation': '45 Emp. L.Q. 123 (2023)',
                    'relevance_score': 0.76,
                    'summary': 'Recent developments in wrongful termination jurisprudence.'
                }
            ]
        }

        # Emit research completed event
        socketio.emit('research_completed', {
            'research_id': research_id,
            'case_id': case_id,
            'evidence_id': evidence_id,
            'status': 'completed',
            'total_sources': research_result['total_sources'],
            'secondary_evidence_ids': research_result['secondary_evidence_ids'],
            'confidence_score': research_result['confidence_score'],
            'timestamp': time.time()
        })

        return jsonify({
            "research_id": research_id,
            "status": "completed",
            "result": research_result,
            "message": f"Research completed with {len(research_result['secondary_evidence_ids'])} SECONDARY evidence entries"
        })

    except Exception as e:
        logger.error(f"Research execution failed: {e}")
        return jsonify({"error": str(e)}), 500

# ============================================================================
# GLOBAL STATE & LLM CONFIGURATION
# ============================================================================

# LLM Configuration (loaded from environment or user settings)
llm_config = {
    "provider": os.getenv("LLM_PROVIDER", "openai"),
    "model": os.getenv("LLM_MODEL", "gpt-4"),
    "api_key": os.getenv("OPENAI_API_KEY") or os.getenv("ANTHROPIC_API_KEY") or os.getenv("GROQ_API_KEY"),
    "temperature": float(os.getenv("LLM_TEMPERATURE", "0.1")),
    "max_tokens": int(os.getenv("LLM_MAX_TOKENS", "2000")),
}

# Global storage for workflow states (temporary - in production use database)
research_status_store = {}
research_results_store = {}
outline_status_store = {}
outline_results_store = {}

# ============================================================================
# ENHANCED EVIDENCE API ROUTES
# ============================================================================

@app.route("/api/evidence", methods=["GET"])
def get_enhanced_evidence_table():
    """Get complete evidence table data with enhanced formatting"""
    try:
        # Create mock evidence data for demonstration
        evidence_list = [
            {
                "evidence_id": "evidence_001",
                "object_id": "obj_12345",
                "filename": "contract.pdf",
                "description": "Employment contract between plaintiff and defendant",
                "evidence_source": "primary",
                "status": "analyzed",
                "file_size": 245760,
                "upload_date": "2024-01-15T10:30:00Z",
                "phase": "phaseA01_intake",
                "tags": "contract, employment, terms",
                "facts": ["Contract executed on 2023-06-01", "Annual salary $85,000"],
                "research_query": "employment contract validity",
                "research_confidence": 0.85,
            },
            {
                "evidence_id": "evidence_002",
                "object_id": "obj_12346",
                "filename": "termination_letter.pdf",
                "description": "Termination notice from HR department",
                "evidence_source": "primary",
                "status": "analyzed",
                "file_size": 189440,
                "upload_date": "2024-01-15T11:15:00Z",
                "phase": "phaseA01_intake",
                "tags": "termination, HR, notice",
                "facts": ["Employment terminated on 2023-12-15", "Reason: performance issues"],
                "research_query": "wrongful termination analysis",
                "research_confidence": 0.92,
            },
            {
                "evidence_id": "evidence_003",
                "object_id": "obj_12347",
                "filename": "case_law_research.pdf",
                "description": "Relevant case law on wrongful termination",
                "evidence_source": "secondary",
                "status": "analyzed",
                "file_size": 567890,
                "upload_date": "2024-01-16T09:45:00Z",
                "phase": "phaseA02_research",
                "tags": "case law, precedent, wrongful termination",
                "facts": ["Similar case: Smith v. ABC Corp (2022)", "Court found for plaintiff"],
                "research_query": "wrongful termination precedents",
                "research_confidence": 0.78,
            }
        ]

        return jsonify({
            "success": True,
            "evidence": evidence_list,
            "total": len(evidence_list),
            "primary_count": len([e for e in evidence_list if e["evidence_source"] == "primary"]),
            "secondary_count": len([e for e in evidence_list if e["evidence_source"] == "secondary"]),
        })
    except Exception as e:
        logger.error(f"Failed to get evidence table: {e}")
        return jsonify({"error": str(e)}), 500


@app.route("/api/evidence", methods=["POST"])
def add_enhanced_evidence_entry():
    """Add new evidence entry with enhanced validation"""
    try:
        data = request.get_json()

        # Validate required fields
        required_fields = ["source_document", "content", "evidence_source"]
        for field in required_fields:
            if not data.get(field):
                return jsonify({"error": f"Field '{field}' is required"}), 400

        # Create evidence entry
        evidence_id = f"evidence_{int(time.time())}"

        evidence_entry = {
            "evidence_id": evidence_id,
            "object_id": data.get("object_id", f"obj_{int(time.time())}"),
            "source_document": data.get("source_document"),
            "page_section": data.get("page_section", ""),
            "content": data.get("content"),
            "evidence_type": data.get("evidence_type", "documentary"),
            "evidence_source": data.get("evidence_source"),  # primary or secondary
            "relevance_score": float(data.get("relevance_score", 0.0)),
            "relevance_level": data.get("relevance_level", "unknown"),
            "bluebook_citation": data.get("bluebook_citation", ""),
            "privilege_marker": data.get("privilege_marker", "none"),
            "extracted_date": data.get("extracted_date"),
            "witness_name": data.get("witness_name"),
            "key_terms": data.get("key_terms", []),
            "notes": data.get("notes", ""),
            "research_query": data.get("research_query"),
            "research_confidence": float(data.get("research_confidence", 0.0)),
            "created_by": data.get("created_by", "user"),
            "created_at": time.time(),
            "status": "stored",
            "phase": data.get("phase", "phaseA01_intake"),
        }

        # In production, save to evidence table
        # evidence_table.add_evidence(evidence_entry)

        # Emit real-time update
        socketio.emit("evidence_added", {
            "evidence": evidence_entry,
            "timestamp": time.time()
        })

        return jsonify({
            "success": True,
            "evidence_id": evidence_id,
            "message": "Evidence entry added successfully",
            "evidence": evidence_entry
        })

    except Exception as e:
        logger.error(f"Failed to add evidence entry: {e}")
        return jsonify({"error": str(e)}), 400


@app.route("/api/evidence/<evidence_id>/download", methods=["GET"])
def download_enhanced_evidence(evidence_id):
    """Download evidence file with enhanced error handling"""
    try:
        # In production, retrieve from unified storage
        # if unified_storage:
        #     result = await unified_storage.get_evidence(evidence_id)
        #     return send_file(BytesIO(result["content"]), ...)

        # Mock download for demonstration
        mock_content = f"Mock content for evidence {evidence_id}"
        from io import BytesIO
        return send_file(
            BytesIO(mock_content.encode('utf-8')),
            mimetype='text/plain',
            as_attachment=True,
            download_name=f"evidence_{evidence_id}.txt"
        )
    except Exception as e:
        logger.error(f"Failed to download evidence {evidence_id}: {e}")
        return jsonify({"error": str(e)}), 500


@app.route("/api/research/execute", methods=["POST"])
def execute_enhanced_research():
    """Execute research from PRIMARY evidence with enhanced error handling"""
    try:
        data = request.get_json()

        case_id = data.get("case_id")
        evidence_id = data.get("evidence_id")
        keywords = data.get("keywords")
        max_results = data.get("max_results", 5)

        if not case_id:
            return jsonify({"error": "case_id is required"}), 400

        # Generate research ID
        research_id = f"research_{int(time.time())}"

        # Emit research started event
        socketio.emit('research_started', {
            'research_id': research_id,
            'case_id': case_id,
            'evidence_id': evidence_id,
            'keywords': keywords or ["auto-extracted"],
            'status': 'processing',
            'timestamp': time.time()
        })

        # Mock research results
        research_result = {
            'research_id': research_id,
            'case_id': case_id,
            'evidence_id': evidence_id,
            'total_sources': 3,
            'secondary_evidence_ids': [f"evidence_{int(time.time()) + i}" for i in range(3)],
            'confidence_score': 0.85,
            'sources': [
                {
                    'title': 'Smith v. ABC Corp Employment Case',
                    'citation': '2022 WL 123456 (Cal. Super. Ct.)',
                    'relevance_score': 0.92,
                    'summary': 'Similar wrongful termination case with favorable outcome for plaintiff.'
                },
                {
                    'title': 'California Labor Code § 2922',
                    'citation': 'Cal. Lab. Code § 2922',
                    'relevance_score': 0.88,
                    'summary': 'Employment at will presumption in California.'
                },
                {
                    'title': 'Employment Law Quarterly Review',
                    'citation': '45 Emp. L.Q. 123 (2023)',
                    'relevance_score': 0.76,
                    'summary': 'Recent developments in wrongful termination jurisprudence.'
                }
            ]
        }

        # Emit research completed event
        socketio.emit('research_completed', {
            'research_id': research_id,
            'case_id': case_id,
            'evidence_id': evidence_id,
            'status': 'completed',
            'total_sources': research_result['total_sources'],
            'secondary_evidence_ids': research_result['secondary_evidence_ids'],
            'confidence_score': research_result['confidence_score'],
            'timestamp': time.time()
        })

        return jsonify({
            "research_id": research_id,
            "status": "completed",
            "result": research_result,
            "message": f"Research completed with {len(research_result['secondary_evidence_ids'])} SECONDARY evidence entries"
        })

    except Exception as e:
        logger.error(f"Research execution failed: {e}")
        return jsonify({"error": str(e)}), 500

# ============================================================================
# GLOBAL STATE & LLM CONFIGURATION
# ============================================================================

# LLM Configuration (loaded from environment or user settings)
llm_config = {
    "provider": os.getenv("LLM_PROVIDER", "openai"),
    "model": os.getenv("LLM_MODEL", "gpt-4"),
    "api_key": os.getenv("OPENAI_API_KEY") or os.getenv("ANTHROPIC_API_KEY") or os.getenv("GROQ_API_KEY"),
    "temperature": float(os.getenv("LLM_TEMPERATURE", "0.1")),
    "max_tokens": int(os.getenv("LLM_MAX_TOKENS", "2000")),
}

# Global storage for workflow states (temporary - in production use database)
research_status_store = {}
research_results_store = {}
outline_status_store = {}
outline_results_store = {}

# ============================================================================
# ENHANCED EVIDENCE API ROUTES
# ============================================================================

@app.route("/api/evidence", methods=["GET"])
def get_enhanced_evidence_table():
    """Get complete evidence table data with enhanced formatting"""
    try:
        # Create mock evidence data for demonstration
        evidence_list = [
            {
                "evidence_id": "evidence_001",
                "object_id": "obj_12345",
                "filename": "contract.pdf",
                "description": "Employment contract between plaintiff and defendant",
                "evidence_source": "primary",
                "status": "analyzed",
                "file_size": 245760,
                "upload_date": "2024-01-15T10:30:00Z",
                "phase": "phaseA01_intake",
                "tags": "contract, employment, terms",
                "facts": ["Contract executed on 2023-06-01", "Annual salary $85,000"],
                "research_query": "employment contract validity",
                "research_confidence": 0.85,
            },
            {
                "evidence_id": "evidence_002",
                "object_id": "obj_12346",
                "filename": "termination_letter.pdf",
                "description": "Termination notice from HR department",
                "evidence_source": "primary",
                "status": "analyzed",
                "file_size": 189440,
                "upload_date": "2024-01-15T11:15:00Z",
                "phase": "phaseA01_intake",
                "tags": "termination, HR, notice",
                "facts": ["Employment terminated on 2023-12-15", "Reason: performance issues"],
                "research_query": "wrongful termination analysis",
                "research_confidence": 0.92,
            },
            {
                "evidence_id": "evidence_003",
                "object_id": "obj_12347",
                "filename": "case_law_research.pdf",
                "description": "Relevant case law on wrongful termination",
                "evidence_source": "secondary",
                "status": "analyzed",
                "file_size": 567890,
                "upload_date": "2024-01-16T09:45:00Z",
                "phase": "phaseA02_research",
                "tags": "case law, precedent, wrongful termination",
                "facts": ["Similar case: Smith v. ABC Corp (2022)", "Court found for plaintiff"],
                "research_query": "wrongful termination precedents",
                "research_confidence": 0.78,
            }
        ]

        return jsonify({
            "success": True,
            "evidence": evidence_list,
            "total": len(evidence_list),
            "primary_count": len([e for e in evidence_list if e["evidence_source"] == "primary"]),
            "secondary_count": len([e for e in evidence_list if e["evidence_source"] == "secondary"]),
        })
    except Exception as e:
        logger.error(f"Failed to get evidence table: {e}")
        return jsonify({"error": str(e)}), 500


@app.route("/api/evidence", methods=["POST"])
def add_enhanced_evidence_entry():
    """Add new evidence entry with enhanced validation"""
    try:
        data = request.get_json()

        # Validate required fields
        required_fields = ["source_document", "content", "evidence_source"]
        for field in required_fields:
            if not data.get(field):
                return jsonify({"error": f"Field '{field}' is required"}), 400

        # Create evidence entry
        evidence_id = f"evidence_{int(time.time())}"

        evidence_entry = {
            "evidence_id": evidence_id,
            "object_id": data.get("object_id", f"obj_{int(time.time())}"),
            "source_document": data.get("source_document"),
            "page_section": data.get("page_section", ""),
            "content": data.get("content"),
            "evidence_type": data.get("evidence_type", "documentary"),
            "evidence_source": data.get("evidence_source"),  # primary or secondary
            "relevance_score": float(data.get("relevance_score", 0.0)),
            "relevance_level": data.get("relevance_level", "unknown"),
            "bluebook_citation": data.get("bluebook_citation", ""),
            "privilege_marker": data.get("privilege_marker", "none"),
            "extracted_date": data.get("extracted_date"),
            "witness_name": data.get("witness_name"),
            "key_terms": data.get("key_terms", []),
            "notes": data.get("notes", ""),
            "research_query": data.get("research_query"),
            "research_confidence": float(data.get("research_confidence", 0.0)),
            "created_by": data.get("created_by", "user"),
            "created_at": time.time(),
            "status": "stored",
            "phase": data.get("phase", "phaseA01_intake"),
        }

        # In production, save to evidence table
        # evidence_table.add_evidence(evidence_entry)

        # Emit real-time update
        socketio.emit("evidence_added", {
            "evidence": evidence_entry,
            "timestamp": time.time()
        })

        return jsonify({
            "success": True,
            "evidence_id": evidence_id,
            "message": "Evidence entry added successfully",
            "evidence": evidence_entry
        })

    except Exception as e:
        logger.error(f"Failed to add evidence entry: {e}")
        return jsonify({"error": str(e)}), 400


@app.route("/api/evidence/<evidence_id>/download", methods=["GET"])
def download_enhanced_evidence(evidence_id):
    """Download evidence file with enhanced error handling"""
    try:
        # In production, retrieve from unified storage
        # if unified_storage:
        #     result = await unified_storage.get_evidence(evidence_id)
        #     return send_file(BytesIO(result["content"]), ...)

        # Mock download for demonstration
        mock_content = f"Mock content for evidence {evidence_id}"
        from io import BytesIO
        return send_file(
            BytesIO(mock_content.encode('utf-8')),
            mimetype='text/plain',
            as_attachment=True,
            download_name=f"evidence_{evidence_id}.txt"
        )
    except Exception as e:
        logger.error(f"Failed to download evidence {evidence_id}: {e}")
        return jsonify({"error": str(e)}), 500


@app.route("/api/research/execute", methods=["POST"])
def execute_enhanced_research():
    """Execute research from PRIMARY evidence with enhanced error handling"""
    try:
        data = request.get_json()

        case_id = data.get("case_id")
        evidence_id = data.get("evidence_id")
        keywords = data.get("keywords")
        max_results = data.get("max_results", 5)

        if not case_id:
            return jsonify({"error": "case_id is required"}), 400

        # Generate research ID
        research_id = f"research_{int(time.time())}"

        # Emit research started event
        socketio.emit('research_started', {
            'research_id': research_id,
            'case_id': case_id,
            'evidence_id': evidence_id,
            'keywords': keywords or ["auto-extracted"],
            'status': 'processing',
            'timestamp': time.time()
        })

        # Mock research results
        research_result = {
            'research_id': research_id,
            'case_id': case_id,
            'evidence_id': evidence_id,
            'total_sources': 3,
            'secondary_evidence_ids': [f"evidence_{int(time.time()) + i}" for i in range(3)],
            'confidence_score': 0.85,
            'sources': [
                {
                    'title': 'Smith v. ABC Corp Employment Case',
                    'citation': '2022 WL 123456 (Cal. Super. Ct.)',
                    'relevance_score': 0.92,
                    'summary': 'Similar wrongful termination case with favorable outcome for plaintiff.'
                },
                {
                    'title': 'California Labor Code § 2922',
                    'citation': 'Cal. Lab. Code § 2922',
                    'relevance_score': 0.88,
                    'summary': 'Employment at will presumption in California.'
                },
                {
                    'title': 'Employment Law Quarterly Review',
                    'citation': '45 Emp. L.Q. 123 (2023)',
                    'relevance_score': 0.76,
                    'summary': 'Recent developments in wrongful termination jurisprudence.'
                }
            ]
        }

        # Emit research completed event
        socketio.emit('research_completed', {
            'research_id': research_id,
            'case_id': case_id,
            'evidence_id': evidence_id,
            'status': 'completed',
            'total_sources': research_result['total_sources'],
            'secondary_evidence_ids': research_result['secondary_evidence_ids'],
            'confidence_score': research_result['confidence_score'],
            'timestamp': time.time()
        })

        return jsonify({
            "research_id": research_id,
            "status": "completed",
            "result": research_result,
            "message": f"Research completed with {len(research_result['secondary_evidence_ids'])} SECONDARY evidence entries"
        })

    except Exception as e:
        logger.error(f"Research execution failed: {e}")
        return jsonify({"error": str(e)}), 500

# ============================================================================
# LAWYERFACTORY COMPONENT IMPORTS WITH FALLBACKS
# ============================================================================

# Component availability flags and instances
LAWYERFACTORY_AVAILABLE = False
research_bot = None
court_authority_helper = None
evidence_table = None
intake_processor = None
outline_generator = None
claims_matrix = None
unified_storage = None
drafting_validator = None
vector_cluster_manager = None

# Import LawyerFactory components with comprehensive fallbacks
try:
    # Core storage component (most critical)
    try:
        from lawyerfactory.storage.core.unified_storage_api import get_enhanced_unified_storage_api
        unified_storage = get_enhanced_unified_storage_api()
        logger.info("✓ EnhancedUnifiedStorageAPI initialized successfully")
    except ImportError:
        get_enhanced_unified_storage_api = None
        unified_storage = None
        logger.warning("EnhancedUnifiedStorageAPI not available")

    # Evidence table component
    try:
        from lawyerfactory.storage.evidence.table import EnhancedEvidenceTable
        evidence_table = EnhancedEvidenceTable()
        logger.info("✓ EnhancedEvidenceTable initialized successfully")
    except ImportError:
        EnhancedEvidenceTable = None
        evidence_table = None
        logger.warning("EnhancedEvidenceTable not available")

    # Research components
    try:
        from lawyerfactory.agents.research.research import ResearchBot
        research_bot = ResearchBot()
        logger.info("✓ ResearchBot initialized successfully")
    except ImportError:
        ResearchBot = None
        research_bot = None
        logger.warning("ResearchBot not available")

    try:
        from lawyerfactory.agents.research.court_authority_helper import CourtAuthorityHelper
        court_authority_helper = CourtAuthorityHelper()
        logger.info("✓ CourtAuthorityHelper initialized successfully")
    except ImportError:
        CourtAuthorityHelper = None
        court_authority_helper = None
        logger.warning("CourtAuthorityHelper not available")

    # Intake components
    try:
        from lawyerfactory.phases.phaseA01_intake.intake_processor import EnhancedIntakeProcessor
        intake_processor = EnhancedIntakeProcessor()
        logger.info("✓ EnhancedIntakeProcessor initialized successfully")
    except ImportError:
        EnhancedIntakeProcessor = None
        intake_processor = None
        logger.warning("EnhancedIntakeProcessor not available")

    # Outline and claims components
    try:
        from lawyerfactory.outline.enhanced_generator import EnhancedSkeletalOutlineGenerator
        outline_generator = EnhancedSkeletalOutlineGenerator()
        logger.info("✓ EnhancedSkeletalOutlineGenerator initialized successfully")
    except ImportError:
        EnhancedSkeletalOutlineGenerator = None
        outline_generator = None
        logger.warning("EnhancedSkeletalOutlineGenerator not available")

    try:
        from lawyerfactory.claims.matrix import ComprehensiveClaimsMatrixIntegration
        claims_matrix = ComprehensiveClaimsMatrixIntegration()
        logger.info("✓ ComprehensiveClaimsMatrixIntegration initialized successfully")
    except ImportError:
        ComprehensiveClaimsMatrixIntegration = None
        claims_matrix = None
        logger.warning("ComprehensiveClaimsMatrixIntegration not available")

    # Drafting components
    try:
        from lawyerfactory.phases.phaseB02_drafting.drafting_validator import DraftingValidator
        from lawyerfactory.phases.phaseA01_intake.vector_cluster_manager import VectorClusterManager
        drafting_validator = DraftingValidator()
        vector_cluster_manager = VectorClusterManager()
        logger.info("✓ Drafting components initialized successfully")
    except ImportError:
        DraftingValidator = None
        VectorClusterManager = None
        drafting_validator = None
        vector_cluster_manager = None
        logger.warning("Drafting components not available")

    LAWYERFACTORY_AVAILABLE = True
    logger.info("✓ All LawyerFactory components initialized successfully")

except ImportError as e:
    logger.warning(f"LawyerFactory components not available: {e}")
    LAWYERFACTORY_AVAILABLE = False

# Global instances
research_bot = None
court_authority_helper = None
evidence_table = None
intake_processor = None
outline_generator = None
claims_matrix = None
unified_storage = None
drafting_validator = None
vector_cluster_manager = None

# LLM Configuration (loaded from environment or user settings)
llm_config = {
    "provider": os.getenv("LLM_PROVIDER", "openai"),
    "model": os.getenv("LLM_MODEL", "gpt-4"),
    "api_key": os.getenv("OPENAI_API_KEY") or os.getenv("ANTHROPIC_API_KEY") or os.getenv("GROQ_API_KEY"),
    "temperature": float(os.getenv("LLM_TEMPERATURE", "0.1")),
    "max_tokens": int(os.getenv("LLM_MAX_TOKENS", "2000")),
}


def initialize_components():
    """Initialize LawyerFactory components with enhanced error handling"""
    global research_bot, court_authority_helper, evidence_table
    global intake_processor, outline_generator, claims_matrix, unified_storage
    global drafting_validator, vector_cluster_manager

    if not LAWYERFACTORY_AVAILABLE:
        logger.warning("LawyerFactory components not available - running in mock mode")
        return

    try:
        # Initialize unified storage first (required by other components)
        if unified_storage is None:
            try:
                if get_enhanced_unified_storage_api:
                    unified_storage = get_enhanced_unified_storage_api()
                    logger.info("✓ Unified storage initialized")
                else:
                    logger.warning("Unified storage API not available")
            except Exception as e:
                logger.warning(f"Failed to initialize unified storage: {e}")
                unified_storage = None

        # Initialize evidence table
        if evidence_table is None:
            try:
                if EnhancedEvidenceTable:
                    evidence_table = EnhancedEvidenceTable()
                    logger.info("✓ Evidence table initialized")
                else:
                    logger.warning("EnhancedEvidenceTable not available")
            except Exception as e:
                logger.warning(f"Failed to initialize evidence table: {e}")
                evidence_table = None

        # Initialize research components
        if research_bot is None:
            try:
                if ResearchBot:
                    research_bot = ResearchBot()
                    logger.info("✓ Research bot initialized")
                else:
                    logger.warning("ResearchBot not available")
            except Exception as e:
                logger.warning(f"Failed to initialize research bot: {e}")
                research_bot = None

        if court_authority_helper is None:
            try:
                if CourtAuthorityHelper:
                    court_authority_helper = CourtAuthorityHelper()
                    logger.info("✓ Court authority helper initialized")
                else:
                    logger.warning("CourtAuthorityHelper not available")
            except Exception as e:
                logger.warning(f"Failed to initialize court authority helper: {e}")
                court_authority_helper = None

        # Initialize intake processor
        if intake_processor is None:
            try:
                if EnhancedIntakeProcessor:
                    intake_processor = EnhancedIntakeProcessor()
                    logger.info("✓ Intake processor initialized")
                else:
                    logger.warning("EnhancedIntakeProcessor not available")
            except Exception as e:
                logger.warning(f"Failed to initialize intake processor: {e}")
                intake_processor = None

        # Initialize drafting components
        if drafting_validator is None:
            try:
                if DraftingValidator:
                    drafting_validator = DraftingValidator()
                    logger.info("✓ Drafting validator initialized")
                else:
                    logger.warning("DraftingValidator not available")
            except Exception as e:
                logger.warning(f"Failed to initialize drafting validator: {e}")
                drafting_validator = None

        if vector_cluster_manager is None:
            try:
                if VectorClusterManager:
                    vector_cluster_manager = VectorClusterManager()
                    logger.info("✓ Vector cluster manager initialized")
                else:
                    logger.warning("VectorClusterManager not available")
            except Exception as e:
                logger.warning(f"Failed to initialize vector cluster manager: {e}")
                vector_cluster_manager = None

        # Initialize outline and claims components
        if outline_generator is None:
            try:
                if EnhancedSkeletalOutlineGenerator:
                    outline_generator = EnhancedSkeletalOutlineGenerator()
                    logger.info("✓ Outline generator initialized")
                else:
                    logger.warning("EnhancedSkeletalOutlineGenerator not available")
            except Exception as e:
                logger.warning(f"Failed to initialize outline generator: {e}")
                outline_generator = None

        if claims_matrix is None:
            try:
                if ComprehensiveClaimsMatrixIntegration:
                    claims_matrix = ComprehensiveClaimsMatrixIntegration()
                    logger.info("✓ Claims matrix initialized")
                else:
                    logger.warning("ComprehensiveClaimsMatrixIntegration not available")
            except Exception as e:
                logger.warning(f"Failed to initialize claims matrix: {e}")
                claims_matrix = None

        # Initialize Flask-compatible evidence API and register routes
        try:
            from apps.api.routes.evidence_flask import FlaskEvidenceAPI
            from apps.api.routes.research_flask import FlaskResearchAPI

            flask_evidence_api = FlaskEvidenceAPI(app=app, storage_path="evidence_table.json")
            flask_research_api = FlaskResearchAPI(app=app, socketio=socketio)
            logger.info("✓ Flask Evidence and Research API routes registered successfully")
        except ImportError as e:
            logger.warning(f"Failed to import Flask Evidence/Research API: {e}")
        except Exception as e:
            logger.warning(f"Failed to initialize Flask Evidence/Research API: {e}")

        logger.info("✓ Component initialization completed successfully")

    except Exception as e:
        logger.error(f"Failed to initialize components: {e}")
        # Set all components to None on initialization failure
        research_bot = None
        court_authority_helper = None
        evidence_table = None
        intake_processor = None
        outline_generator = None
        claims_matrix = None
        unified_storage = None
        drafting_validator = None
        vector_cluster_manager = None


# Initialize components on startup
initialize_components()

# Test route to verify Flask is working
@app.route("/api/test")
def test_route():
    return jsonify({"status": "Flask routes working"})

# Register Socket.IO instance for phase events
try:
    from src.lawyerfactory.phases.socket_events import set_socketio_instance
    set_socketio_instance(socketio)
    logger.info("Socket.IO instance registered for phase events")
except ImportError as e:
    logger.warning(f"Could not import phase socket events: {e}")


# Socket.IO event handlers
@socketio.on("connect")
def handle_connect():
    logger.info("Client connected")
    emit("status", {"message": "Connected to LawyerFactory API"})


@socketio.on("disconnect")
def handle_disconnect():
    logger.info("Client disconnected")


# API Routes


@app.route("/api/health", methods=["GET"])
def health_check():
    """Health check endpoint"""
    return jsonify(
        {
            "status": "healthy",
            "lawyerfactory_available": LAWYERFACTORY_AVAILABLE,
            "components": {
                "research_bot": research_bot is not None,
                "court_authority_helper": court_authority_helper is not None,
                "evidence_table": evidence_table is not None,
                "intake_processor": intake_processor is not None,
                "outline_generator": outline_generator is not None,
                "claims_matrix": claims_matrix is not None,
            },
        }
    )


@app.route("/api/intake", methods=["POST"])
def process_intake():
    """Process legal intake form and create case"""
    if not LAWYERFACTORY_AVAILABLE or not intake_processor:
        return jsonify({"error": "Intake processor not available"}), 503

    try:
        data = request.get_json()

        # Process intake data
        intake_result = intake_processor.process_intake_form(data)

        # Create case in storage
        case_id = f"case_{int(time.time())}"

        # Emit progress update
        socketio.emit(
            "phase_progress_update",
            {
                "phase": "A01_Intake",
                "progress": 100,
                "message": f"Case {case_id} created successfully",
            },
        )

        return jsonify({"success": True, "case": intake_result, "case_id": case_id})

    except Exception as e:
        logger.error(f"Intake processing failed: {e}")
        return jsonify({"error": str(e)}), 500


@app.route("/api/cases/<case_id>/documents", methods=["POST"])
def upload_case_documents(case_id):
    """Upload documents for a specific case"""
    if not LAWYERFACTORY_AVAILABLE or not intake_processor:
        return jsonify({"error": "Document processor not available"}), 503

    try:
        files = request.files.getlist("files")

        # Process documents
        processed_docs = []
        for file in files:
            # Save file temporarily
            temp_path = f"/tmp/{file.filename}"
            file.save(temp_path)

            # Process document
            doc_result = intake_processor.process_document(temp_path, case_id)
            processed_docs.append(doc_result)

            # Clean up temp file
            os.remove(temp_path)

        # Emit progress update
        socketio.emit(
            "phase_progress_update",
            {
                "phase": "A01_Intake",
                "progress": 75,
                "message": f"Processed {len(processed_docs)} documents for case {case_id}",
            },
        )

        return jsonify(
            {"success": True, "uploaded_files": processed_docs, "total": len(processed_docs)}
        )

    except Exception as e:
        logger.error(f"Document upload failed: {e}")
        return jsonify({"error": str(e)}), 500


# Global storage for workflow states (temporary - in production use database)
research_status_store = {}
research_results_store = {}
outline_status_store = {}
outline_results_store = {}


@app.route("/api/research/start", methods=["POST"])
def start_research():
    """Start research for a case"""
    if not LAWYERFACTORY_AVAILABLE or not research_bot:
        return jsonify({"error": "Research bot not available"}), 503

    try:
        data = request.get_json()
        case_id = data.get("case_id")
        research_query = data.get("query", "")

        if not case_id:
            return jsonify({"error": "Case ID required"}), 400

        # Start research asynchronously
        socketio.start_background_task(run_research, case_id, research_query)

        return jsonify({"success": True, "message": "Research started", "case_id": case_id})

    except Exception as e:
        logger.error(f"Research start failed: {e}")
        return jsonify({"error": str(e)}), 500


@app.route("/api/research/status/<case_id>", methods=["GET"])
def get_research_status(case_id):
    """Get research status for a case"""
    if not LAWYERFACTORY_AVAILABLE or not research_bot:
        return jsonify({"error": "Research bot not available"}), 503

    try:
        # Get research status from temporary store
        status = research_status_store.get(
            case_id, {"status": "not_started", "progress": 0, "message": "Research not yet started"}
        )

        return jsonify(
            {
                "case_id": case_id,
                "status": status.get("status", "unknown"),
                "progress": status.get("progress", 0),
                "message": status.get("message", ""),
            }
        )

    except Exception as e:
        logger.error(f"Research status check failed: {e}")
        return jsonify({"error": str(e)}), 500


@app.route("/api/research/results/<case_id>", methods=["GET"])
def get_research_results(case_id):
    """Get research results for a case"""
    if not LAWYERFACTORY_AVAILABLE or not research_bot:
        return jsonify({"error": "Research bot not available"}), 503

    try:
        # Get research results from temporary store
        results = research_results_store.get(
            case_id,
            {
                "sources": [],
                "legal_principles": [],
                "gaps": [],
                "recommendations": [],
                "confidence_score": 0.0,
            },
        )

        return jsonify(
            {
                "case_id": case_id,
                "results": results,
                "total_sources": len(results.get("sources", [])),
            }
        )

    except Exception as e:
        logger.error(f"Research results retrieval failed: {e}")
        return jsonify({"error": str(e)}), 500


@app.route("/api/outline/generate", methods=["POST"])
def generate_outline():
    """Generate document outline for a case"""
    if not LAWYERFACTORY_AVAILABLE or not outline_generator:
        return jsonify({"error": "Outline generator not available"}), 503

    try:
        data = request.get_json()
        case_id = data.get("case_id")

        if not case_id:
            return jsonify({"error": "Case ID required"}), 400

        # Generate outline asynchronously
        socketio.start_background_task(run_outline_generation, case_id)

        return jsonify(
            {"success": True, "message": "Outline generation started", "case_id": case_id}
        )

    except Exception as e:
        logger.error(f"Outline generation start failed: {e}")
        return jsonify({"error": str(e)}), 500


@app.route("/api/outline/status/<case_id>", methods=["GET"])
def get_outline_status(case_id):
    """Get outline generation status"""
    try:
        # Return mock status for now
        return jsonify(
            {
                "success": True,
                "case_id": case_id,
                "status": "completed",
                "message": "Outline generation status",
            }
        )
    except Exception as e:
        logger.error(f"Failed to get outline status: {e}")
        return jsonify({"success": False, "error": str(e)}), 500


# ============================================================================
# UNIFIED PHASE ORCHESTRATION ENDPOINT
# ============================================================================


@app.route("/api/phases/<phase_id>/start", methods=["POST"])
def start_phase(phase_id):
    """
    Unified phase orchestration endpoint
    Routes phase requests to appropriate handlers with Socket.IO integration
    
    Supported phases:
    - phaseA01_intake: Document categorization and fact extraction
    - phaseA02_research: Legal research and authority gathering
    - phaseA03_outline: Case structure and claims development
    - phaseB01_review: Quality assurance and validation
    - phaseB02_drafting: Document composition
    - phaseC01_editing: Content refinement and formatting
    - phaseC02_orchestration: Final workflow coordination
    """
    data = request.get_json() or {}
    case_id = data.get("case_id")
    
    if not case_id:
        return jsonify({"error": "case_id required"}), 400
    
    logger.info(f"Starting phase {phase_id} for case {case_id}")
    
    # Phase routing map
    phase_handlers = {
        "phaseA01_intake": handle_intake_phase,
        "phaseA02_research": handle_research_phase,
        "phaseA03_outline": handle_outline_phase,
        "phaseB01_review": handle_review_phase,
        "phaseB02_drafting": handle_drafting_phase,
        "phaseC01_editing": handle_editing_phase,
        "phaseC02_orchestration": handle_orchestration_phase,
    }
    
    handler = phase_handlers.get(phase_id)
    if not handler:
        return jsonify({"error": f"Unknown phase: {phase_id}"}), 404
    
    try:
        # Emit phase started event
        socketio.emit("phase_started", {
            "phase": phase_id,
            "case_id": case_id,
            "timestamp": time.time()
        })
        
        # Execute phase handler
        import asyncio
        if asyncio.iscoroutinefunction(handler):
            # Handle async handlers
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                result = loop.run_until_complete(handler(case_id, data))
            finally:
                loop.close()
        else:
            # Handle sync handlers
            result = handler(case_id, data)
        
        # Emit phase completed event
        socketio.emit("phase_completed", {
            "phase": phase_id,
            "case_id": case_id,
            "result": result,
            "timestamp": time.time()
        })
        
        return jsonify({
            "success": True,
            "phase": phase_id,
            "case_id": case_id,
            "result": result
        })
        
    except Exception as e:
        logger.error(f"Phase {phase_id} failed for case {case_id}: {e}")
        
        # Emit phase error event
        socketio.emit("phase_error", {
            "phase": phase_id,
            "case_id": case_id,
            "error": str(e),
            "timestamp": time.time()
        })
        
        return jsonify({"error": str(e)}), 500


def handle_intake_phase(case_id: str, data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Phase A01: Document Intake
    Categorizes documents and extracts facts using Reader agent
    """
    # Extract LLM config from request data
    llm_config_request = {
        "provider": data.get("llm_provider", llm_config.get("provider", "openai")),
        "model": data.get("llm_model", llm_config.get("model", "gpt-4")),
        "temperature": float(data.get("llm_temperature", llm_config.get("temperature", 0.1))),
        "max_tokens": int(data.get("llm_max_tokens", llm_config.get("max_tokens", 2000))),
        "api_key": data.get("llm_api_key", llm_config.get("api_key"))
    }
    
    socketio.emit("phase_progress_update", {
        "phase": "A01_Intake",
        "progress": 10,
        "message": f"Initializing intake processor with {llm_config_request['provider']}/{llm_config_request['model']}..."
    })
    
    if not intake_processor or not INTAKE_PROCESSOR_AVAILABLE:
        logger.warning("Intake processor not available, using mock mode")
        socketio.emit("phase_progress_update", {
            "phase": "A01_Intake",
            "progress": 100,
            "message": "Intake complete (mock mode)"
        })
        return {
            "status": "mock",
            "message": "Intake processor not available - mock data returned",
            "documents_processed": 0
        }
    
    try:
        socketio.emit("phase_progress_update", {
            "phase": "A01_Intake",
            "progress": 30,
            "message": "Categorizing documents..."
        })
        
        # Process intake using existing logic
        files = data.get("files", [])
        
        socketio.emit("phase_progress_update", {
            "phase": "A01_Intake",
            "progress": 60,
            "message": "Extracting facts and metadata..."
        })
        
        result = {
            "status": "completed",
            "case_id": case_id,
            "documents_processed": len(data.get("files", [])),
            "facts_extracted": True
        }
        
        socketio.emit("phase_progress_update", {
            "phase": "A01_Intake",
            "progress": 100,
            "message": "✅ Intake complete"
        })
        
        return result
        
    except Exception as e:
        logger.error(f"Intake phase error: {e}")
        raise


def handle_research_phase(case_id: str, data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Phase A02: Legal Research
    Gathers legal authorities and precedents using Paralegal and Researcher agents
    """
    # Extract LLM config from request data
    llm_config_request = {
        "provider": data.get("llm_provider", llm_config.get("provider", "openai")),
        "model": data.get("llm_model", llm_config.get("model", "gpt-4")),
        "temperature": float(data.get("llm_temperature", llm_config.get("temperature", 0.1))),
        "max_tokens": int(data.get("llm_max_tokens", llm_config.get("max_tokens", 2000))),
        "api_key": data.get("llm_api_key", llm_config.get("api_key"))
    }
    
    socketio.emit("phase_progress_update", {
        "phase": "A02_Research",
        "progress": 10,
        "message": f"Initializing research agents with {llm_config_request['provider']}/{llm_config_request['model']}..."
    })
    
    if not research_bot or not RESEARCH_BOT_AVAILABLE:
        logger.warning("Research bot not available, using mock mode")
        socketio.emit("phase_progress_update", {
            "phase": "A02_Research",
            "progress": 100,
            "message": "Research complete (mock mode)"
        })
        return {
            "status": "mock",
            "message": "Research bot not available - mock data returned",
            "authorities_found": 0
        }
    
    try:
        research_query = data.get("research_query", "Legal research")
        
        socketio.emit("phase_progress_update", {
            "phase": "A02_Research",
            "progress": 30,
            "message": "Searching legal databases..."
        })
        
        socketio.emit("phase_progress_update", {
            "phase": "A02_Research",
            "progress": 60,
            "message": "Analyzing case law and statutes..."
        })
        
        result = {
            "status": "completed",
            "case_id": case_id,
            "research_query": data.get("research_query", "Legal research"),
            "authorities_found": 0
            
        }
        
        socketio.emit("phase_progress_update", {
            "phase": "A02_Research",
            "progress": 100,
            "message": "🔍 Research complete"
        })
        
        return result
        
    except Exception as e:
        logger.error(f"Research phase error: {e}")
        raise


def handle_outline_phase(case_id: str, data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Phase A03: Case Outline
    Structures claims and develops case theory using Outliner agent
    """
    # Extract LLM config from request data
    llm_config_request = {
        "provider": data.get("llm_provider", llm_config.get("provider", "openai")),
        "model": data.get("llm_model", llm_config.get("model", "gpt-4")),
        "temperature": float(data.get("llm_temperature", llm_config.get("temperature", 0.1))),
        "max_tokens": int(data.get("llm_max_tokens", llm_config.get("max_tokens", 2000))),
        "api_key": data.get("llm_api_key", llm_config.get("api_key"))
    }
    
    socketio.emit("phase_progress_update", {
        "phase": "A03_Outline",
        "progress": 10,
        "message": f"Initializing outline generator with {llm_config_request['provider']}/{llm_config_request['model']}..."
    })
    
    if not outline_generator or not OUTLINE_GENERATOR_AVAILABLE:
        logger.warning("Outline generator not available, using mock mode")
        socketio.emit("phase_progress_update", {
            "phase": "A03_Outline",
            "progress": 100,
            "message": "Outline complete (mock mode)"
        })
        return {
            "status": "mock",
            "message": "Outline generator not available - mock data returned",
            "claims_identified": 0
        }
    
    try:
        socketio.emit("phase_progress_update", {
            "phase": "A03_Outline",
            "progress": 30,
            "message": "Analyzing case structure..."
        })
        
        socketio.emit("phase_progress_update", {
            "phase": "A03_Outline",
            "progress": 60,
            "message": "Developing claims matrix..."
        })
        
        result = {
            "status": "completed",
            "case_id": case_id,
            "claims_identified": 0,
            "outline_generated": True
        }
        
        socketio.emit("phase_progress_update", {
            "phase": "A03_Outline",
            "progress": 100,
            "message": "📋 Outline complete"
        })
        
        return result
        
    except Exception as e:
        logger.error(f"Outline phase error: {e}")
        raise


def handle_review_phase(case_id: str, data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Phase B01: Quality Review
    Validates deliverables from Phase A03 before allowing drafting to proceed.
    Checks:
    - Shotlist has minimum facts (10+)
    - Claims matrix has all required elements
    - Skeletal outline has required sections
    - Rule 12(b)(6) compliance score >= 75
    """
    socketio.emit("phase_progress_update", {
        "phase": "phaseB01_review",
        "case_id": case_id,
        "progress": 10,
        "message": "Loading Phase A03 deliverables..."
    })
    
    try:
        deliverables_dir = Path(f"./workflow_storage/cases/{case_id}/deliverables")
        
        if not deliverables_dir.exists():
            return {
                "status": "error",
                "message": "No deliverables found. Please complete Phase A03 first.",
                "case_id": case_id,
                "ready_for_drafting": False
            }
        
        validations = {}
        
        # Validate Shotlist
        socketio.emit("phase_progress_update", {
            "phase": "phaseB01_review",
            "case_id": case_id,
            "progress": 25,
            "message": "Validating shotlist timeline..."
        })
        
        shotlist_path = deliverables_dir / "shotlist.csv"
        if shotlist_path.exists():
            import csv
            with open(shotlist_path, 'r') as f:
                reader = csv.DictReader(f)
                shotlist_facts = list(reader)
                fact_count = len(shotlist_facts)
                validations["shotlist_facts"] = {
                    "passed": fact_count >= 10,
                    "message": f"{fact_count} facts (minimum 10 required)",
                    "count": fact_count
                }
        else:
            validations["shotlist_facts"] = {
                "passed": False,
                "message": "Shotlist not found",
                "count": 0
            }
        
        # Validate Claims Matrix
        socketio.emit("phase_progress_update", {
            "phase": "phaseB01_review",
            "case_id": case_id,
            "progress": 50,
            "message": "Validating claims matrix..."
        })
        
        claims_path = deliverables_dir / "claims_matrix.json"
        if claims_path.exists():
            with open(claims_path, 'r') as f:
                claims_data = json.load(f)
                element_analysis = claims_data.get("element_analysis", {})
                elements_count = len(element_analysis)
                
                # Check if all elements have decision outcomes
                all_elements_complete = all(
                    elem.get("decision_outcome") is not None
                    for elem in element_analysis.values()
                )
                
                validations["claims_elements"] = {
                    "passed": elements_count > 0 and all_elements_complete,
                    "message": f"{elements_count} elements analyzed" if all_elements_complete else "Incomplete element analysis",
                    "count": elements_count
                }
        else:
            validations["claims_elements"] = {
                "passed": False,
                "message": "Claims matrix not found",
                "count": 0
            }
        
        # Validate Skeletal Outline
        socketio.emit("phase_progress_update", {
            "phase": "phaseB01_review",
            "case_id": case_id,
            "progress": 75,
            "message": "Validating skeletal outline..."
        })
        
        outline_path = deliverables_dir / "skeletal_outline.json"
        required_sections = ["caption", "introduction", "jurisdiction", "parties", "statement_of_facts"]
        
        if outline_path.exists():
            with open(outline_path, 'r') as f:
                outline_data = json.load(f)
                sections = outline_data.get("sections", [])
                section_ids = [s.get("id") for s in sections]
                
                has_required_sections = all(
                    req_section in section_ids
                    for req_section in required_sections
                )
                
                validations["outline_sections"] = {
                    "passed": has_required_sections and len(sections) >= 5,
                    "message": f"{len(sections)} sections" if has_required_sections else "Missing required sections",
                    "count": len(sections)
                }
                
                # Check Rule 12(b)(6) score
                rule12b6_score = outline_data.get("rule12b6ComplianceScore", 0)
                validations["rule_12b6_score"] = {
                    "passed": rule12b6_score >= 86,
                    "message": f"Score: {rule12b6_score}% (minimum 86%)",
                    "score": rule12b6_score
                }
        else:
            validations["outline_sections"] = {
                "passed": False,
                "message": "Skeletal outline not found",
                "count": 0
            }
            validations["rule_12b6_score"] = {
                "passed": False,
                "message": "No compliance score available",
                "score": 0
            }
        
        # Overall validation
        all_valid = all(v.get("passed", False) for v in validations.values())
        
        socketio.emit("phase_progress_update", {
            "phase": "phaseB01_review",
            "case_id": case_id,
            "progress": 100,
            "message": "✅ Validation complete" if all_valid else "⚠️ Validation issues found"
        })
        
        return {
            "status": "completed" if all_valid else "requires_attention",
            "case_id": case_id,
            "validations": validations,
            "all_valid": all_valid,
            "ready_for_drafting": all_valid,
            "message": "All deliverables validated successfully" if all_valid else "Some validations failed - review deliverables before proceeding"
        }
        
    except Exception as e:
        logger.error(f"Phase B01 validation error for case {case_id}: {e}")
        return {
            "status": "error",
            "case_id": case_id,
            "error": str(e),
            "ready_for_drafting": False
        }


async def handle_drafting_phase(case_id: str, data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Phase B02: Document Drafting - Sequential IRAC + RAG + Multi-Agent Approach
    
    Execution flow:
    1. Load skeletal outline sections sequentially
    2. For each section, identify ISSUE using nested IRAC
    3. Retrieve applicable jurisdiction-appropriate RULE via vectorized RAG search
    4. Apply rule to issue with evidence citations
    5. Reach conclusion; if rule gap found, request research; if logic gap detected, notify EditorBot
    6. Repeat until all sections complete
    
    Integrates:
    - Skeletal Outline: Section prompts driving workflow
    - IRAC Templates: Nested Issue-Rule-Application-Conclusion structure
    - Vector RAG: Semantic search for evidence, case law, and legal facts
    - Multi-Agent Swarm: WriterBot (drafting) + EditorBot (validation) + Maestro (orchestration)
    - Evidence Table: Primary/secondary evidence access with citations
    """
    # Extract LLM config from request data
    llm_config_request = {
        "provider": data.get("llm_provider", llm_config.get("provider", "openai")),
        "model": data.get("llm_model", llm_config.get("model", "gpt-4")),
        "temperature": float(data.get("llm_temperature", llm_config.get("temperature", 0.1))),
        "max_tokens": int(data.get("llm_max_tokens", llm_config.get("max_tokens", 2000))),
        "api_key": data.get("llm_api_key", llm_config.get("api_key"))
    }
    
    socketio.emit("phase_progress_update", {
        "phase": "phaseB02_drafting",
        "case_id": case_id,
        "progress": 5,
        "message": f"🚀 Initializing sequential IRAC + RAG drafting with {llm_config_request['provider']}/{llm_config_request['model']}..."
    })

    try:
        # STEP 1: Load approved deliverables from Phase A03
        deliverables_dir = Path(f"./workflow_storage/cases/{case_id}/deliverables")
        
        if not deliverables_dir.exists():
            return {
                "status": "error",
                "message": "No approved deliverables found. Complete Phase B01 review first.",
                "case_id": case_id
            }
        
        socketio.emit("phase_progress_update", {
            "phase": "phaseB02_drafting",
            "case_id": case_id,
            "progress": 10,
            "message": "📂 Loading skeletal outline, claims matrix, evidence table, and shotlist..."
        })
        
        # Load deliverables
        shotlist_facts = []
        claims_matrix_data = {}
        skeletal_outline_data = {}
        
        # Load Shotlist (evidence facts)
        shotlist_path = deliverables_dir / "shotlist.csv"
        if shotlist_path.exists():
            import csv
            with open(shotlist_path, 'r') as f:
                reader = csv.DictReader(f)
                shotlist_facts = list(reader)
        
        # Load Claims Matrix (element analysis)
        claims_path = deliverables_dir / "claims_matrix.json"
        if claims_path.exists():
            with open(claims_path, 'r') as f:
                claims_matrix_data = json.load(f)
        
        # Load Skeletal Outline (section prompts for sequential processing)
        outline_path = deliverables_dir / "skeletal_outline.json"
        if outline_path.exists():
            with open(outline_path, 'r') as f:
                skeletal_outline_data = json.load(f)
        
        logger.info(f"Loaded: {len(shotlist_facts)} evidence facts, "
                   f"{len(claims_matrix_data.get('element_analysis', {}))} claim elements, "
                   f"{len(skeletal_outline_data.get('sections', []))} skeleton sections")
        
        socketio.emit("phase_progress_update", {
            "phase": "phaseB02_drafting",
            "case_id": case_id,
            "progress": 15,
            "message": f"✅ Loaded {len(skeletal_outline_data.get('sections', []))} sections to draft sequentially"
        })
        
        # STEP 2: Initialize core components for sequential IRAC + RAG
        try:
            from lawyerfactory.compose.promptkits.irac_templates import (
                IRACTemplateEngine,
                claims_matrix_to_irac
            )
            irac_available = True
        except ImportError as e:
            logger.warning(f"IRAC templates not available: {e}")
            irac_available = False
        
        try:
            from lawyerfactory.compose.bots.writer import WriterBot
            from lawyerfactory.compose.bots.editor import LegalEditorBot
            from lawyerfactory.agents.orchestration.maestro import Maestro
            bots_available = True
        except ImportError as e:
            logger.warning(f"Bots not available: {e}")
            bots_available = False
        
        # Initialize unified storage for vectorized RAG search
        unified_storage_instance = unified_storage
        if not unified_storage_instance:
            try:
                from lawyerfactory.storage.core.unified_storage_api import get_enhanced_unified_storage_api
                unified_storage_instance = get_enhanced_unified_storage_api()
            except ImportError as e:
                logger.warning(f"Unified storage not available for RAG: {e}")
                unified_storage_instance = None
        
        socketio.emit("phase_progress_update", {
            "phase": "phaseB02_drafting",
            "case_id": case_id,
            "progress": 25,
            "message": "🤖 Initializing WriterBot, EditorBot, and Maestro orchestrator..."
        })
        
        # Fallback if core components unavailable
        if not (bots_available and irac_available):
            logger.warning("Core drafting components unavailable, using fallback")
            complaint_text = f"UNITED STATES DISTRICT COURT\n{data.get('district', 'NORTHERN DISTRICT OF CALIFORNIA')}\n\n{data.get('plaintiff_name', 'PLAINTIFF')} v. {data.get('defendant_name', 'DEFENDANT')}\n\nCase No. {case_id}\n\nCOMPLAINT\n\n"
            for i, fact in enumerate(shotlist_facts[:20], 1):
                complaint_text += f"{i}. {fact.get('summary', '')}\n\n"
            output_dir = Path(f"./workflow_storage/cases/{case_id}/drafts")
            output_dir.mkdir(parents=True, exist_ok=True)
            with open(output_dir / "complaint_draft.txt", 'w') as f:
                f.write(complaint_text)
            return {"status": "completed", "case_id": case_id, "fallback_mode": True, "word_count": len(complaint_text.split())}
        
        # Initialize multi-agent swarm
        maestro = Maestro()
        from lawyerfactory.compose.agent_registry import AgentConfig
        agent_config = AgentConfig(agent_type="WriterBot", config={"llm": llm_config_request})
        writer_bot = WriterBot(agent_config=agent_config)
        editor_bot = LegalEditorBot(agent_config=agent_config)
        
        # STEP 3: Sequential section processing with nested IRAC + RAG
        drafted_sections = []
        sections = skeletal_outline_data.get('sections', [])
        total_sections = len(sections)
        research_requests = []  # Track research gaps
        logic_gaps = []  # Track EditorBot findings
        
        for idx, section in enumerate(sections):
            section_id = section.get('id', f'section_{idx}')
            section_title = section.get('title', 'Untitled Section')
            
            progress = 25 + int((idx / total_sections) * 65)  # 25% to 90%
            socketio.emit("phase_progress_update", {
                "phase": "phaseB02_drafting",
                "case_id": case_id,
                "progress": progress,
                "message": f"📝 Sequential IRAC: {section_title} (Section {idx+1}/{total_sections})"
            })
            
            try:
                # STEP 3.1: Identify ISSUE from section prompt
                issue_identification = {
                    "section_id": section_id,
                    "section_title": section_title,
                    "issue": section.get('summary', section_title),
                    "claims_affected": section.get('relatedClaims', [])
                }
                
                # STEP 3.2: Retrieve applicable RULE via vectorized RAG search
                rag_context = []
                supporting_authorities = []
                
                if unified_storage_instance:
                    try:
                        # Vector search for relevant evidence and case law
                        search_query = f"{section_title} {issue_identification['issue']}"
                        rag_results = await unified_storage_instance.search_evidence(
                            query=search_query,
                            search_tier="vector"
                        )
                        rag_context = [
                            result.get('vector_data', {}).get('content', '')[:300]
                            for result in rag_results[:5]
                        ]
                        supporting_authorities = [
                            {
                                "object_id": result.get('object_id'),
                                "relevance_score": result.get('relevance_score', 0.0)
                            }
                            for result in rag_results[:3]
                        ]
                        logger.info(f"RAG found {len(rag_results)} sources for {section_title}")
                    except Exception as e:
                        logger.warning(f"RAG search failed for {section_title}: {e}")
                
                # STEP 3.3: Get relevant facts and build IRAC prompt
                relevant_facts = [
                    fact for fact in shotlist_facts
                    if section_id.lower() in fact.get('summary', '').lower()
                    or any(claim.lower() in fact.get('summary', '').lower() 
                           for claim in issue_identification.get('claims_affected', []))
                ][:15]
                
                if not relevant_facts:
                    relevant_facts = shotlist_facts[:10]
                
                # Build nested IRAC prompt
                if section_id.startswith('cause_'):
                    # Cause of action: full IRAC structure
                    irac_section = claims_matrix_to_irac(claims_matrix_data, relevant_facts)
                    irac_prompt = IRACTemplateEngine.generate_nested_irac_prompt(
                        irac_section=irac_section,
                        shotlist_facts=relevant_facts,
                        include_examples=True
                    )
                    section_type = "cause_of_action_irac"
                elif section_id == 'statement_of_facts':
                    # Statement of facts from shotlist
                    irac_prompt = IRACTemplateEngine.generate_statement_of_facts(
                        shotlist_facts=shotlist_facts,
                        chronological=True
                    )
                    section_type = "statement_of_facts"
                else:
                    # Generic section with IRAC context
                    irac_prompt = IRACTemplateEngine.build_section_prompt(
                        section_type="nested_irac",
                        section_data=section,
                        shotlist_facts=relevant_facts,
                        claims_matrix=claims_matrix_data,
                        rag_context=rag_context
                    )
                    section_type = "generic_irac"
                
                # Inject RAG context into prompt
                full_prompt = f"{irac_prompt}\n\n--- RAG-Enhanced Legal Context ---\n{chr(10).join(rag_context) if rag_context else 'No additional context found'}\n\n--- Supporting Authorities ---\n{len(supporting_authorities)} sources retrieved"
                
                # STEP 3.4: Apply Rule to Issue (WriterBot drafts section)
                section_draft = await writer_bot.draft_section(
                    prompt=full_prompt,
                    section_id=section_id,
                    max_words=section.get('estimatedWords', 400),
                    context={
                        "case_id": case_id,
                        "issue": issue_identification['issue'],
                        "supporting_facts": [f.get('summary', '') for f in relevant_facts[:5]],
                        "rag_authorities": supporting_authorities
                    }
                )
                
                # STEP 3.5: EditorBot validates logic and legal reasoning
                editor_validation = await editor_bot.validate_section(
                    section_content=section_draft,
                    section_type=section_type,
                    claims_matrix=claims_matrix_data,
                    evidence_facts=relevant_facts,
                    required_elements=section.get('requiredElements', [])
                )
                
                # Check for gaps identified by EditorBot
                if not editor_validation.get('valid', True):
                    gap_details = {
                        "section_id": section_id,
                        "gap_type": editor_validation.get('gap_type', 'unknown'),
                        "description": editor_validation.get('feedback', 'Validation failed'),
                        "action_required": editor_validation.get('action_required', 'manual_review')
                    }
                    logic_gaps.append(gap_details)
                    
                    # If rule is missing (not logic gap), request research
                    if "rule not found" in editor_validation.get('feedback', '').lower():
                        research_requests.append({
                            "section_id": section_id,
                            "issue": issue_identification['issue'],
                            "research_query": f"Legal rule for {section_title}",
                            "priority": "high"
                        })
                        logger.info(f"Research requested for {section_title}: {editor_validation.get('feedback')}")
                
                # STEP 3.6: Assemble completed section
                drafted_sections.append({
                    "section_id": section_id,
                    "title": section_title,
                    "content": section_draft,
                    "word_count": len(section_draft.split()),
                    "issue": issue_identification['issue'],
                    "rag_sources_used": len(supporting_authorities),
                    "logic_valid": editor_validation.get('valid', False),
                    "validation_feedback": editor_validation.get('feedback', '')
                })
                
                logger.info(f"✓ Section {section_id}: {len(section_draft.split())} words, "
                           f"RAG sources: {len(supporting_authorities)}, "
                           f"Logic valid: {editor_validation.get('valid', False)}")
                
            except Exception as e:
                logger.error(f"Error drafting section {section_id}: {e}")
                drafted_sections.append({
                    "section_id": section_id,
                    "title": section_title,
                    "content": f"[Section {section_title} - DRAFT ERROR: {str(e)}]",
                    "word_count": 0,
                    "error": str(e)
                })
        
        # STEP 4: Post-drafting orchestration and research handling
        socketio.emit("phase_progress_update", {
            "phase": "phaseB02_drafting",
            "case_id": case_id,
            "progress": 90,
            "message": f"🔍 Validating draft integrity and logic ({len(logic_gaps)} gaps detected, {len(research_requests)} research requests)..."
        })
        
        # Use Maestro to coordinate any follow-up research if gaps found
        if research_requests and research_bot:
            logger.info(f"Maestro initiating on-demand research for {len(research_requests)} gaps")
            for req in research_requests:
                try:
                    await research_bot.conduct_targeted_research(
                        query=req['research_query'],
                        case_id=case_id,
                        priority=req['priority']
                    )
                except Exception as e:
                    logger.warning(f"On-demand research failed: {e}")
        
        # STEP 5: Assemble final complaint and save
        socketio.emit("phase_progress_update", {
            "phase": "phaseB02_drafting",
            "case_id": case_id,
            "progress": 95,
            "message": "📄 Assembling final IRAC-driven complaint..."
        })
        
        complaint_parts = []
        for section in drafted_sections:
            complaint_parts.append(f"\n\n{'='*80}\n{section['title'].upper()}\n{'='*80}\n\n")
            complaint_parts.append(section['content'])
        
        full_complaint = "".join(complaint_parts)
        total_word_count = sum(s['word_count'] for s in drafted_sections)
        
        output_dir = Path(f"./workflow_storage/cases/{case_id}/drafts")
        output_dir.mkdir(parents=True, exist_ok=True)
        draft_path = output_dir / "complaint_draft.txt"
        
        with open(draft_path, 'w') as f:
            f.write(full_complaint)
        
        # Save detailed metadata
        draft_json_path = output_dir / "complaint_draft.json"
        draft_data = {
            "case_id": case_id,
            "sections": drafted_sections,
            "total_word_count": total_word_count,
            "generated_at": time.time(),
            "method": "sequential_nested_irac_rag",
            "rag_enhanced": unified_storage_instance is not None,
            "logic_gaps_detected": len(logic_gaps),
            "research_requests": len(research_requests),
            "logic_gaps": logic_gaps,
            "research_requests": research_requests
        }
        
        with open(draft_json_path, 'w') as f:
            json.dump(draft_data, f, indent=2)
        
        socketio.emit("phase_progress_update", {
            "phase": "phaseB02_drafting",
            "case_id": case_id,
            "progress": 100,
            "message": f"✅ Sequential IRAC drafting complete: {total_word_count} words, {len(drafted_sections)} sections, {len(logic_gaps)} gaps, {len(research_requests)} research requests"
        })
        
        return {
            "status": "completed",
            "case_id": case_id,
            "draft_path": str(draft_path),
            "draft_json_path": str(draft_json_path),
            "word_count": total_word_count,
            "sections_completed": len(drafted_sections),
            "method": "sequential_nested_irac_rag",
            "rag_enhanced": unified_storage_instance is not None,
            "logic_gaps_detected": len(logic_gaps),
            "research_requests_generated": len(research_requests),
            "message": "Complaint drafted using sequential nested IRAC with RAG enhancement"
        }
        
    except Exception as e:
        logger.error(f"Phase B02 sequential IRAC drafting error for case {case_id}: {e}")
        import traceback
        traceback.print_exc()
        
        return {
            "status": "error",
            "case_id": case_id,
            "error": str(e),
            "message": "Sequential IRAC drafting failed - see logs for details"
        }


def handle_editing_phase(case_id: str, data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Phase C01: Final Editing
    Polishes and formats documents using Legal Formatter agent
    (STUB - To be implemented with proper formatter agent integration)
    """
    socketio.emit("phase_progress_update", {
        "phase": "C01_Editing",
        "progress": 30,
        "message": "Formatting citations..."
    })
    
    time.sleep(1)
    
    socketio.emit("phase_progress_update", {
        "phase": "C01_Editing",
        "progress": 70,
        "message": "Polishing content..."
    })
    
    time.sleep(1)
    
    socketio.emit("phase_progress_update", {
        "phase": "C01_Editing",
        "progress": 100,
        "message": "✏️ Editing complete (mock)"
    })
    
    return {
        "status": "mock",
        "message": "Editing phase not yet implemented - placeholder complete",
        "case_id": case_id,
        "documents_formatted": 0
    }


def handle_orchestration_phase(case_id: str, data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Phase C02: Final Orchestration
    Coordinates final workflow and deliverables using Maestro agent
    (STUB - To be implemented with proper orchestration agent integration)
    """
    socketio.emit("phase_progress_update", {
        "phase": "C02_Orchestration",
        "progress": 30,
        "message": "Coordinating final deliverables..."
    })
    
    time.sleep(1)
    
    socketio.emit("phase_progress_update", {
        "phase": "C02_Orchestration",
        "progress": 70,
        "message": "Packaging documents..."
    })
    
    time.sleep(1)
    
    socketio.emit("phase_progress_update", {
        "phase": "C02_Orchestration",
        "progress": 100,
        "message": "🎯 Orchestration complete (mock)"
    })
    
    return {
        "status": "mock",
        "message": "Orchestration phase not yet implemented - placeholder complete",
        "case_id": case_id,
        "deliverables_ready": True
    }


@app.route("/api/storage/documents", methods=["POST"])
def upload_documents_unified():
    """Upload documents using unified storage API"""
    if not unified_storage:
        return jsonify({"error": "Unified storage not available"}), 503

    try:
        files = request.files.getlist("files")
        case_id = request.form.get("case_id", "default")
        phase = request.form.get("phase", "phaseA01_intake")

        if not files:
            return jsonify({"error": "No files provided"}), 400

        results = []

        for file in files:
            if file.filename == "":
                continue

            # Read file content
            file_content = file.read()

            # Create metadata for evidence storage
            metadata = {
                "case_id": case_id,
                "filename": file.filename,
                "content_type": file.content_type or "application/octet-stream",
                "uploaded_at": time.time(),
                "phase": phase,
                "source": "frontend_upload",
            }

            # Store using unified storage API
            result = unified_storage.store_evidence(
                file_content=file_content,
                filename=file.filename,
                metadata=metadata,
                source_phase=phase,
            )

            if result.success:
                results.append(
                    {
                        "filename": file.filename,
                        "object_id": result.object_id,
                        "evidence_id": result.evidence_id,
                        "s3_url": result.s3_url,
                        "size": len(file_content),
                        "processing_time": result.processing_time,
                    }
                )
            else:
                logger.error(f"Failed to store {file.filename}: {result.error}")
                return jsonify({"error": f"Failed to store {file.filename}: {result.error}"}), 500

        # Emit progress update
        socketio.emit(
            "phase_progress_update",
            {
                "phase": phase,
                "progress": 100,
                "message": f"Stored {len(results)} documents in unified storage",
                "case_id": case_id,
                "object_ids": [r["object_id"] for r in results],
            },
        )

        logger.info(
            f"Successfully stored {len(results)} documents via unified storage for case {case_id}"
        )

        return jsonify(
            {
                "success": True,
                "case_id": case_id,
                "stored_documents": results,
                "total": len(results),
                "message": f"Successfully stored {len(results)} documents",
            }
        )

    except Exception as e:
        logger.error(f"Unified document storage failed: {e}")
        return jsonify({"error": str(e)}), 500


@app.route("/api/storage/documents/<object_id>", methods=["GET"])
def get_document_by_object_id(object_id):
    """Retrieve document from unified storage by ObjectID"""
    if not unified_storage:
        return jsonify({"error": "Unified storage not available"}), 503

    try:
        # Retrieve document using unified storage API
        document_data = unified_storage.retrieve_evidence_by_id(object_id)

        if document_data:
            return jsonify(
                {
                    "success": True,
                    "object_id": object_id,
                    "document": document_data,
                    "retrieved_at": time.time(),
                }
            )
        else:
            return jsonify({"error": "Document not found"}), 404

    except Exception as e:
        logger.error(f"Failed to retrieve document {object_id}: {e}")
        return jsonify({"error": str(e)}), 500


@app.route("/api/storage/cases/<case_id>/documents", methods=["GET"])
def get_case_documents(case_id):
    """Retrieve all documents for a case from unified storage"""
    if not unified_storage:
        return jsonify({"error": "Unified storage not available"}), 503

    try:
        # Search for documents by case_id in metadata
        documents = unified_storage.search_evidence_by_metadata({"case_id": case_id})

        return jsonify(
            {
                "success": True,
                "case_id": case_id,
                "documents": documents,
                "total": len(documents),
                "retrieved_at": time.time(),
            }
        )

    except Exception as e:
        logger.error(f"Failed to retrieve documents for case {case_id}: {e}")
        return jsonify({"error": str(e)}), 500


# ============================================================================
# CLAIMS MATRIX API ENDPOINTS
# ============================================================================

@app.route("/api/claims/matrix/<case_id>", methods=["GET"])
def get_claims_matrix(case_id):
    """Get claims matrix for a case using vectorized evidence"""
    if not LAWYERFACTORY_AVAILABLE or not unified_storage:
        return jsonify({"error": "Claims matrix service not available"}), 503

    try:
        # Get all documents for this case
        case_documents = unified_storage.search_evidence_by_metadata({"case_id": case_id})
        
        # Extract content from documents for analysis
        evidence_texts = []
        for doc in case_documents:
            if isinstance(doc, dict) and "content" in doc:
                evidence_texts.append(doc["content"])
            elif hasattr(doc, "content"):
                evidence_texts.append(doc.content)
        
        # Generate claims matrix from evidence (synchronous for Flask)
        claims_matrix = generate_claims_matrix_from_evidence(case_id, evidence_texts)
        
        return jsonify({
            "success": True,
            "case_id": case_id,
            "claims": claims_matrix,
            "evidence_count": len(evidence_texts),
            "generated_at": time.time()
        })
        
    except Exception as e:
        logger.error(f"Failed to generate claims matrix for case {case_id}: {e}")
        return jsonify({"error": str(e)}), 500


def generate_claims_matrix_from_evidence(case_id: str, evidence_texts: List[str]) -> List[Dict[str, Any]]:
    """Generate claims matrix using analysis of evidence"""
    try:
        # For now, return a mock claims matrix based on common legal patterns
        # In production, this would use LLM analysis with RAG context
        
        mock_claims = [
            {
                "id": "breach_of_contract",
                "name": "Breach of Contract",
                "jurisdiction": "California",
                "elements": [
                    {
                        "name": "Existence of Contract",
                        "description": "Valid contract between parties with clear terms",
                        "status": "proven" if len(evidence_texts) > 0 else "pending",
                        "evidenceCount": len([t for t in evidence_texts if "contract" in t.lower() or "agreement" in t.lower()])
                    },
                    {
                        "name": "Plaintiff's Performance",
                        "description": "Plaintiff substantially performed contractual obligations",
                        "status": "pending",
                        "evidenceCount": 0
                    },
                    {
                        "name": "Defendant's Breach",
                        "description": "Defendant failed to perform contractual obligations",
                        "status": "pending",
                        "evidenceCount": 0
                    },
                    {
                        "name": "Damages",
                        "description": "Plaintiff suffered measurable damages from breach",
                        "status": "pending",
                        "evidenceCount": 0
                    }
                ],
                "analysis": "Based on evidence analysis, contract breach appears viable. Further evidence needed for performance and damages elements.",
                "confidence_score": 0.75
            }
        ]
        
        # If we have evidence with specific keywords, add more claims
        evidence_combined = " ".join(evidence_texts).lower()
        
        if "negligence" in evidence_combined or "care" in evidence_combined:
            mock_claims.append({
                "id": "negligence",
                "name": "Negligence",
                "jurisdiction": "California",
                "elements": [
                    {
                        "name": "Duty of Care",
                        "description": "Defendant owed plaintiff a duty of reasonable care",
                        "status": "pending",
                        "evidenceCount": 0
                    },
                    {
                        "name": "Breach of Duty",
                        "description": "Defendant breached the duty of care",
                        "status": "pending",
                        "evidenceCount": 0
                    },
                    {
                        "name": "Causation",
                        "description": "Breach caused plaintiff's damages",
                        "status": "pending",
                        "evidenceCount": 0
                    },
                    {
                        "name": "Damages",
                        "description": "Plaintiff suffered compensable damages",
                        "status": "pending",
                        "evidenceCount": 0
                    }
                ],
                "analysis": "Negligence claim detected in evidence. Requires analysis of duty, breach, causation, and damages.",
                "confidence_score": 0.60
            })
        
        return mock_claims
        
    except Exception as e:
        logger.error(f"Error generating claims matrix: {e}")
        return []


# ============================================================================
# SKELETAL OUTLINE API ENDPOINTS
# ============================================================================

@app.route("/api/outline/generate/<case_id>", methods=["POST"])
def generate_skeletal_outline(case_id):
    """Generate skeletal outline using RAG-enhanced analysis"""
    if not LAWYERFACTORY_AVAILABLE or not unified_storage:
        return jsonify({"error": "Outline generation service not available"}), 503

    try:
        data = request.get_json() or {}
        claims_matrix = data.get("claims_matrix", [])
        shot_list = data.get("shot_list", [])
        
        # Get relevant evidence using RAG (synchronous for Flask)
        rag_context = get_rag_context_for_outline(case_id, claims_matrix, shot_list)
        
        # Generate outline using RAG-enhanced approach
        outline = generate_rag_enhanced_outline(case_id, claims_matrix, shot_list, rag_context)
        
        return jsonify({
            "success": True,
            "case_id": case_id,
            "outline": outline,
            "rag_context_used": len(rag_context),
            "generated_at": time.time()
        })
        
    except Exception as e:
        logger.error(f"Failed to generate skeletal outline for case {case_id}: {e}")
        return jsonify({"error": str(e)}), 500


def get_rag_context_for_outline(case_id: str, claims_matrix: List[Dict], shot_list: List[Dict]) -> List[str]:
    """Get RAG context relevant to outline generation"""
    try:
        if not unified_storage:
            return []
        
        # Create search queries based on claims
        search_queries = []
        for claim in claims_matrix:
            search_queries.append(f"legal requirements for {claim.get('name', '')}")
            for element in claim.get('elements', []):
                search_queries.append(f"evidence needed for {element.get('name', '')}")
        
        # Search for relevant context (simplified synchronous version)
        all_context = []
        for query in search_queries[:3]:  # Limit to avoid too many searches
            try:
                # Use synchronous search method if available, otherwise skip
                if hasattr(unified_storage, 'search_evidence'):
                    context = unified_storage.search_evidence(query, search_tier="vector")
                    all_context.extend([c.get("content", "") for c in context if isinstance(c, dict)])
            except Exception as e:
                logger.warning(f"RAG search failed for query '{query}': {e}")
        
        return all_context[:10]  # Limit context
        
    except Exception as e:
        logger.error(f"Error getting RAG context: {e}")
        return []


def generate_rag_enhanced_outline(case_id: str, claims_matrix: List[Dict], shot_list: List[Dict], rag_context: List[str]) -> Dict[str, Any]:
    """Generate outline using RAG-enhanced analysis"""
    try:
        # Mock outline generation - in production would use LLM with RAG context
        sections = [
            {
                "id": "caption",
                "title": "Case Caption",
                "status": "pending",
                "content": "",
                "required": True,
                "estimatedWords": 50,
                "rag_context": len([c for c in rag_context if "caption" in c.lower() or "court" in c.lower()])
            },
            {
                "id": "introduction", 
                "title": "Introduction",
                "status": "pending",
                "content": "",
                "required": True,
                "estimatedWords": 200,
                "rag_context": len([c for c in rag_context if "introduction" in c.lower() or "action" in c.lower()])
            },
            {
                "id": "jurisdiction",
                "title": "Jurisdiction and Venue", 
                "status": "pending",
                "content": "",
                "required": True,
                "estimatedWords": 150,
                "rag_context": len([c for c in rag_context if "jurisdiction" in c.lower() or "venue" in c.lower()])
            },
            {
                "id": "parties",
                "title": "Parties",
                "status": "pending", 
                "content": "",
                "required": True,
                "estimatedWords": 100,
                "rag_context": len([c for c in rag_context if "party" in c.lower() or "plaintiff" in c.lower() or "defendant" in c.lower()])
            },
            {
                "id": "facts",
                "title": "Statement of Facts",
                "status": "pending",
                "content": "",
                "required": True,
                "estimatedWords": 500,
                "rag_context": len(shot_list)  # Use shot list as fact context
            }
        ]
        
        # Add claims sections
        for i, claim in enumerate(claims_matrix):
            sections.append({
                "id": f"cause_{i}",
                "title": f"Cause of Action: {claim.get('name', f'Claim {i+1}')}",
                "status": "pending",
                "content": "",
                "required": True,
                "estimatedWords": 300,
                "claimData": claim,
                "rag_context": len([c for c in rag_context if claim.get('name', '').lower() in c.lower()])
            })
        
        # Add conclusion sections
        sections.extend([
            {
                "id": "relief",
                "title": "Prayer for Relief",
                "status": "pending",
                "content": "",
                "required": True,
                "estimatedWords": 100,
                "rag_context": len([c for c in rag_context if "relief" in c.lower() or "damages" in c.lower()])
            },
            {
                "id": "jury",
                "title": "Jury Demand", 
                "status": "pending",
                "content": "",
                "required": True,
                "estimatedWords": 50,
                "rag_context": 0
            }
        ])
        
        outline = {
            "id": f"outline_{case_id}_{int(time.time())}",
            "caseId": case_id,
            "sections": sections,
            "totalEstimatedWords": sum(s["estimatedWords"] for s in sections),
            "generationDate": time.time(),
            "status": "draft",
            "rule12b6ComplianceScore": 85,  # Mock compliance score
            "rag_context_used": len(rag_context),
            "claims_integrated": len(claims_matrix),
            "evidence_facts": len(shot_list)
        }
        
        return outline
        
    except Exception as e:
        logger.error(f"Error generating RAG-enhanced outline: {e}")
        return {
            "id": f"outline_{case_id}_error",
            "caseId": case_id,
            "sections": [],
            "error": str(e)
        }


# Background task functions
def run_research(case_id: str, research_query: str):
    """Run research in background"""
    try:
        # Update status to running
        research_status_store[case_id] = {
            "status": "running",
            "progress": 10,
            "message": "Initializing research...",
        }

        # Emit progress update
        socketio.emit(
            "phase_progress_update",
            {"phase": "A02_Research", "progress": 10, "message": "Research initialized"},
        )

        # Run research
        results = research_bot.research_case(case_id, research_query)

        # Update status to completed
        research_status_store[case_id] = {
            "status": "completed",
            "progress": 100,
            "message": "Research completed",
        }
        research_results_store[case_id] = results

        # Emit completion update
        socketio.emit(
            "phase_progress_update",
            {
                "phase": "A02_Research",
                "progress": 100,
                "message": f'Research completed with {len(results.get("sources", []))} sources found',
            },
        )

        # Trigger evidence feedback loop if new sources found
        if len(results.get("sources", [])) > 0:
            socketio.start_background_task(process_research_feedback, case_id, results)

    except Exception as e:
        logger.error(f"Research failed: {e}")
        research_status_store[case_id] = {"status": "failed", "progress": 0, "message": str(e)}

        socketio.emit(
            "phase_progress_update",
            {"phase": "A02_Research", "progress": 0, "message": f"Research failed: {str(e)}"},
        )


def run_outline_generation(case_id: str):
    """Run outline generation in background"""
    try:
        # Update status to running
        outline_status_store[case_id] = {
            "status": "running",
            "progress": 10,
            "message": "Initializing outline generation...",
        }

        # Emit progress update
        socketio.emit(
            "phase_progress_update",
            {"phase": "A03_Outline", "progress": 10, "message": "Outline generation initialized"},
        )

        # Generate outline
        import asyncio

        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            outline = loop.run_until_complete(
                outline_generator.generate_enhanced_outline(case_id, f"session_{case_id}")
            )
        finally:
            loop.close()

        # Update status to completed
        outline_status_store[case_id] = {
            "status": "completed",
            "progress": 100,
            "message": "Outline generation completed",
        }
        outline_results_store[case_id] = outline

        # Emit completion update
        socketio.emit(
            "phase_progress_update",
            {
                "phase": "A03_Outline",
                "progress": 100,
                "message": f'Outline generated with {len(outline.get("sections", []))} sections',
            },
        )

    except Exception as e:
        logger.error(f"Outline generation failed: {e}")
        outline_status_store[case_id] = {"status": "failed", "progress": 0, "message": str(e)}

        socketio.emit(
            "phase_progress_update",
            {
                "phase": "A03_Outline",
                "progress": 0,
                "message": f"Outline generation failed: {str(e)}",
            },
        )


def process_research_feedback(case_id: str, research_results: Dict[str, Any]):
    """Process research results back through evidence intake"""
    try:
        new_sources_count = 0
        max_sources = 10  # Stop after finding 10 new sources

        for source in research_results.get("sources", []):
            if new_sources_count >= max_sources:
                break

            # Check if source already exists in evidence
            if not evidence_table.source_exists(source.get("citation", "")):
                # Add new source to evidence table
                evidence_entry = {
                    "source_document": source.get("title", ""),
                    "content": source.get("summary", ""),
                    "evidence_type": "secondary_authority",
                    "relevance_score": source.get("relevance_score", 0.5),
                    "bluebook_citation": source.get("citation", ""),
                    "key_terms": source.get("key_terms", []),
                    "notes": f"Found via research for case {case_id}",
                }

                evidence_table.add_evidence(evidence_entry)
                new_sources_count += 1

        if new_sources_count > 0:
            socketio.emit(
                "phase_progress_update",
                {
                    "phase": "A02_Research",
                    "progress": 100,
                    "message": f"Added {new_sources_count} new sources to evidence table",
                },
            )

    except Exception as e:
        logger.error(f"Research feedback processing failed: {e}")
 "status": "healthy",
            "message": "LawyerFactory Canonical API Server is running",
            "timestamp": time.time(),
            "version": "2.1.0-canonical",
            "features": {
                "phase_orchestration": True,
                "evidence_management": True,
                "research_integration": True,
                "real_time_updates": True,
                "unified_storage": False,  # Will be enabled when storage is available
                "llm_integration": True,
            }
        }
    )


# ============================================================================
# SOCKET.IO EVENT HANDLERS
# ============================================================================


# ============================================================================
# PHASE A03 - OUTLINE GENERATION DELIVERABLES API
# ============================================================================

@app.route("/api/phaseA03/shotlist/<case_id>", methods=["POST"])
def generate_shotlist(case_id):
    """
    Generate chronological shotlist (timeline) from all PRIMARY and SECONDARY evidence
    Returns JSON representation and stores CSV file as deliverable
    """
    if not LAWYERFACTORY_AVAILABLE or not unified_storage:
        return jsonify({"error": "Shotlist generation service not available"}), 503
    
    if not PHASE_A03_AVAILABLE or not build_shot_list:
        return jsonify({"error": "Phase A03 shotlist component not available"}), 503
    
    try:
        logger.info(f"Generating shotlist for case {case_id}")
        
        # Fetch all evidence for this case (PRIMARY + SECONDARY)
        all_evidence = []
        try:
            if hasattr(unified_storage, 'get_case_documents'):
                evidence_objects = unified_storage.get_case_documents(case_id)
                all_evidence = evidence_objects if isinstance(evidence_objects, list) else []
        except Exception as e:
            logger.warning(f"Could not fetch evidence from unified storage: {e}")
        
        # If no evidence from storage, try evidence table
        if not all_evidence and evidence_table:
            try:
                all_evidence = evidence_table.get_all_evidence()
                # Filter by case_id if metadata exists
                all_evidence = [e for e in all_evidence if e.get("case_id") == case_id or e.get("metadata", {}).get("case_id") == case_id]
            except Exception as e:
                logger.warning(f"Could not fetch evidence from evidence table: {e}")
        
        if not all_evidence:
            return jsonify({
                "error": "No evidence found for this case",
                "case_id": case_id,
                "evidence_count": 0
            }), 404
        
        # Transform evidence into shotlist format (chronological facts)
        evidence_rows = []
        for idx, evidence in enumerate(all_evidence):
            # Extract metadata
            metadata = evidence.get("metadata", {}) if isinstance(evidence, dict) else {}
            content = evidence.get("content", evidence.get("text", ""))
            
            # Create fact entry
            fact_entry = {
                "fact_id": f"fact_{case_id}_{idx+1}",
                "source_id": evidence.get("object_id", evidence.get("id", f"evidence_{idx+1}")),
                "timestamp": evidence.get("timestamp", evidence.get("created_at", metadata.get("timestamp", ""))),
                "summary": content[:500] if isinstance(content, str) else str(content)[:500],  # First 500 chars as summary
                "entities": metadata.get("entities", metadata.get("parties", [])),
                "citations": metadata.get("citations", [])
            }
            evidence_rows.append(fact_entry)
        
        # Sort by timestamp (chronological order)
        def safe_timestamp(fact):
            ts = fact.get("timestamp", "")
            if isinstance(ts, str) and ts:
                return ts
            return "9999-12-31"  # Put facts without timestamp at end
        
        evidence_rows.sort(key=safe_timestamp)
        
        # Validate evidence rows
        if validate_evidence_rows:
            validation_report = validate_evidence_rows(evidence_rows)
            logger.info(f"Shotlist validation: {validation_report}")
        
        # Generate CSV shotlist
        output_dir = Path(f"./workflow_storage/cases/{case_id}/deliverables")
        output_dir.mkdir(parents=True, exist_ok=True)
        csv_path = output_dir / "shotlist.csv"
        
        csv_file_path = build_shot_list(evidence_rows, csv_path)
        logger.info(f"Shotlist CSV generated at {csv_file_path}")
        
        # Emit Socket.IO event for real-time update
        socketio.emit("shotlist_generated", {
            "case_id": case_id,
            "fact_count": len(evidence_rows),
            "csv_path": str(csv_file_path),
            "timestamp": time.time()
        })
        
        return jsonify({
            "success": True,
            "case_id": case_id,
            "shotlist": evidence_rows,  # JSON representation
            "fact_count": len(evidence_rows),
            "csv_path": str(csv_file_path),
            "download_url": f"/api/deliverables/{case_id}/shotlist.csv",
            "generated_at": time.time()
        })
        
    except Exception as e:
        logger.error(f"Failed to generate shotlist for case {case_id}: {e}")
        return jsonify({"error": str(e)}), 500


@app.route("/api/phaseA03/claims-matrix/<case_id>", methods=["POST"])
def generate_claims_matrix_endpoint(case_id):
    """
    Generate claims matrix from evidence using ComprehensiveClaimsMatrixIntegration
    Analyzes all evidence to detect potential legal claims and elements
    """
    if not LAWYERFACTORY_AVAILABLE or not unified_storage:
        return jsonify({"error": "Claims matrix generation service not available"}), 503
    
    if not PHASE_A03_AVAILABLE or not ClaimsMatrixPhaseA03:
        # Fallback to mock generation if Phase A03 not available
        logger.warning("Phase A03 claims matrix not available, using mock generation")
        evidence_texts = []
        try:
            all_evidence = unified_storage.get_case_documents(case_id) if hasattr(unified_storage, 'get_case_documents') else []
            evidence_texts = [e.get("content", e.get("text", "")) for e in all_evidence if isinstance(e, dict)]
        except:
            pass
        
        claims_matrix = generate_claims_matrix_from_evidence(case_id, evidence_texts)
        
        return jsonify({
            "success": True,
            "case_id": case_id,
            "claims_matrix": claims_matrix,
            "mock_data": True,
            "generated_at": time.time()
        })
    
    try:
        logger.info(f"Generating claims matrix for case {case_id}")
        data = request.get_json() or {}
        jurisdiction = data.get("jurisdiction", "ca_state")  # Default to California
        
        # Fetch all evidence
        all_evidence = []
        try:
            if hasattr(unified_storage, 'get_case_documents'):
                all_evidence = unified_storage.get_case_documents(case_id)
        except Exception as e:
            logger.warning(f"Could not fetch evidence: {e}")
        
        # Transform evidence into case facts format
        case_facts = []
        for idx, evidence in enumerate(all_evidence):
            if isinstance(evidence, dict):
                fact = {
                    "id": evidence.get("object_id", f"fact_{idx}"),
                    "name": f"Evidence {idx+1}",
                    "description": evidence.get("content", evidence.get("text", ""))[:500],
                    "type": evidence.get("metadata", {}).get("document_type", "evidence")
                }
                case_facts.append(fact)
        
        # Initialize claims matrix integration
        # Note: This requires EnhancedKnowledgeGraph which may not be available
        # If not available, fall back to mock generation
        try:
            from lawyerfactory.kg.graph_api import EnhancedKnowledgeGraph
            kg = EnhancedKnowledgeGraph(f"./workflow_storage/cases/{case_id}/knowledge_graph.db")
            claims_integration = ClaimsMatrixPhaseA03(kg)
            
            # Start interactive analysis
            session_id = claims_integration.start_interactive_analysis(
                jurisdiction=jurisdiction,
                cause_of_action=data.get("cause_of_action", "negligence"),
                case_facts=case_facts
            )
            
            # Generate comprehensive definition
            definition = claims_integration.get_comprehensive_definition(session_id)
            
            # Generate attorney-ready analysis
            attorney_analysis = claims_integration.generate_attorney_ready_analysis(session_id)
            
            # Export as structured report
            claims_report = claims_integration.export_analysis_report(attorney_analysis, "comprehensive")
            
            # Close KG
            kg.close()
            
            # Save to file
            output_dir = Path(f"./workflow_storage/cases/{case_id}/deliverables")
            output_dir.mkdir(parents=True, exist_ok=True)
            json_path = output_dir / "claims_matrix.json"
            
            with open(json_path, 'w') as f:
                json.dump(claims_report, f, indent=2)
            
            logger.info(f"Claims matrix JSON generated at {json_path}")
            
            # Emit Socket.IO event
            socketio.emit("claims_matrix_generated", {
                "case_id": case_id,
                "session_id": session_id,
                "claims_count": len(attorney_analysis.element_breakdowns) if attorney_analysis else 0,
                "json_path": str(json_path),
                "timestamp": time.time()
            })
            
            return jsonify({
                "success": True,
                "case_id": case_id,
                "session_id": session_id,
                "claims_matrix": claims_report,
                "json_path": str(json_path),
                "download_url": f"/api/deliverables/{case_id}/claims_matrix.json",
                "generated_at": time.time()
            })
            
        except ImportError as e:
            logger.warning(f"EnhancedKnowledgeGraph not available, using mock: {e}")
            # Fallback to mock generation
            evidence_texts = [f.get("description", "") for f in case_facts]
            claims_matrix = generate_claims_matrix_from_evidence(case_id, evidence_texts)
            
            # Save mock data
            output_dir = Path(f"./workflow_storage/cases/{case_id}/deliverables")
            output_dir.mkdir(parents=True, exist_ok=True)
            json_path = output_dir / "claims_matrix.json"
            
            with open(json_path, 'w') as f:
                json.dump(claims_matrix, f, indent=2)
            
            return jsonify({
                "success": True,
                "case_id": case_id,
                "claims_matrix": claims_matrix,
                "mock_data": True,
                "json_path": str(json_path),
                "download_url": f"/api/deliverables/{case_id}/claims_matrix.json",
                "generated_at": time.time()
            })
        
    except Exception as e:
        logger.error(f"Failed to generate claims matrix for case {case_id}: {e}")
        return jsonify({"error": str(e)}), 500


@app.route("/api/phaseA03/generate/<case_id>", methods=["POST"])
def generate_phase_a03_deliverables(case_id):
    """
    Orchestrate Phase A03 deliverable generation:
    1. Generate shotlist (chronological facts timeline)
    2. Generate claims matrix (legal analysis)
    3. Generate skeletal outline (from shotlist + claims matrix)
    Returns all three deliverables with download links
    """
    if not LAWYERFACTORY_AVAILABLE or not unified_storage:
        return jsonify({"error": "Phase A03 generation service not available"}), 503
    
    try:
        logger.info(f"Starting Phase A03 deliverable generation for case {case_id}")
        data = request.get_json() or {}
        
        # Emit progress update
        socketio.emit("phase_progress_update", {
            "phase": "phaseA03_outline",
            "case_id": case_id,
            "status": "running",
            "progress": 10,
            "message": "Starting Phase A03 deliverable generation..."
        })
        
        # Step 1: Generate shotlist
        logger.info(f"Step 1/3: Generating shotlist for case {case_id}")
        socketio.emit("phase_progress_update", {
            "phase": "phaseA03_outline",
            "case_id": case_id,
            "status": "running",
            "progress": 25,
            "message": "Generating chronological shotlist timeline..."
        })
        
        shotlist_response = generate_shotlist(case_id)
        shotlist_data = shotlist_response.get_json() if hasattr(shotlist_response, 'get_json') else {}
        
        if not shotlist_data.get("success"):
            raise Exception(f"Shotlist generation failed: {shotlist_data.get('error', 'Unknown error')}")
        
        shotlist = shotlist_data.get("shotlist", [])
        logger.info(f"Shotlist generated with {len(shotlist)} facts")
        
        # Step 2: Generate claims matrix
        logger.info(f"Step 2/3: Generating claims matrix for case {case_id}")
        socketio.emit("phase_progress_update", {
            "phase": "phaseA03_outline",
            "case_id": case_id,
            "status": "running",
            "progress": 50,
            "message": "Analyzing evidence for legal claims..."
        })
        
        # Pass jurisdiction and cause_of_action from request data
        claims_request_data = {
            "jurisdiction": data.get("jurisdiction", "ca_state"),
            "cause_of_action": data.get("cause_of_action", "negligence")
        }
        
        # Create a request context for generate_claims_matrix_endpoint
        with app.test_request_context(
            f"/api/phaseA03/claims-matrix/{case_id}",
            method="POST",
            json=claims_request_data
        ):
            claims_response = generate_claims_matrix_endpoint(case_id)
            claims_data = claims_response.get_json() if hasattr(claims_response, 'get_json') else {}
        
        if not claims_data.get("success"):
            raise Exception(f"Claims matrix generation failed: {claims_data.get('error', 'Unknown error')}")
        
        claims_matrix = claims_data.get("claims_matrix", [])
        logger.info(f"Claims matrix generated")
        
        # Step 3: Generate skeletal outline using shotlist + claims matrix
        logger.info(f"Step 3/3: Generating skeletal outline for case {case_id}")
        socketio.emit("phase_progress_update", {
            "phase": "phaseA03_outline",
            "case_id": case_id,
            "status": "running",
            "progress": 75,
            "message": "Generating skeletal outline from timeline and claims..."
        })
        
        # Create outline request with shotlist and claims matrix
        outline_request_data = {
            "claims_matrix": claims_matrix if isinstance(claims_matrix, list) else [],
            "shot_list": shotlist
        }
        
        # Use existing generate_skeletal_outline endpoint
        with app.test_request_context(
            f"/api/outline/generate/{case_id}",
            method="POST",
            json=outline_request_data
        ):
            outline_response = generate_skeletal_outline(case_id)
            outline_data = outline_response.get_json() if hasattr(outline_response, 'get_json') else {}
        
        if not outline_data.get("success"):
            logger.warning(f"Skeletal outline generation had issues: {outline_data.get('error', 'Unknown')}")
            # Continue anyway with available data
        
        outline = outline_data.get("outline", {})
        
        # Save skeletal outline as deliverable
        output_dir = Path(f"./workflow_storage/cases/{case_id}/deliverables")
        output_dir.mkdir(parents=True, exist_ok=True)
        outline_json_path = output_dir / "skeletal_outline.json"
        
        with open(outline_json_path, 'w') as f:
            json.dump(outline, f, indent=2)
        
        logger.info(f"Skeletal outline JSON generated at {outline_json_path}")
        
        # Emit final completion event
        socketio.emit("skeletal_outline_generated", {
            "case_id": case_id,
            "json_path": str(outline_json_path),
            "section_count": len(outline.get("sections", [])),
            "timestamp": time.time()
        })
        
        socketio.emit("phase_progress_update", {
            "phase": "phaseA03_outline",
            "case_id": case_id,
            "status": "completed",
            "progress": 100,
            "message": "Phase A03 deliverables generated successfully"
        })
        
        # Return all deliverables
        return jsonify({
            "success": True,
            "case_id": case_id,
            "deliverables": {
                "shotlist": {
                    "data": shotlist,
                    "fact_count": len(shotlist),
                    "download_url": f"/api/deliverables/{case_id}/shotlist.csv"
                },
                "claims_matrix": {
                    "data": claims_matrix,
                    "download_url": f"/api/deliverables/{case_id}/claims_matrix.json"
                },
                "skeletal_outline": {
                    "data": outline,
                    "section_count": len(outline.get("sections", [])),
                    "download_url": f"/api/deliverables/{case_id}/skeletal_outline.json"
                }
            },
            "generated_at": time.time()
        })
        
    except Exception as e:
        logger.error(f"Failed to generate Phase A03 deliverables for case {case_id}: {e}")
        
        socketio.emit("phase_progress_update", {
            "phase": "phaseA03_outline",
            "case_id": case_id,
            "status": "failed",
            "progress": 0,
            "message": f"Phase A03 generation failed: {str(e)}"
        })
        
        return jsonify({"error": str(e)}), 500


@app.route("/api/phases/phaseB01_review/validate/<case_id>", methods=["POST"])
def validate_deliverables_endpoint(case_id):
    """
    Validate Phase A03 deliverables before allowing approval
    Checks:
    - Shotlist has minimum 10 facts
    - Claims matrix has complete element analysis
    - Skeletal outline has required sections
    - Rule 12(b)(6) compliance score >= 75
    """
    try:
        logger.info(f"Validating deliverables for case {case_id}")
        
        # Call the validation logic from Phase B01 handler
        validation_result = handle_review_phase(case_id, {})
        
        return jsonify({
            "success": validation_result.get("all_valid", False),
            "validations": validation_result.get("validations", {}),
            "all_valid": validation_result.get("all_valid", False),
            "ready_for_drafting": validation_result.get("ready_for_drafting", False),
            "message": validation_result.get("message", "")
        })
        
    except Exception as e:
        logger.error(f"Validation failed for case {case_id}: {e}")
        return jsonify({"error": str(e), "success": False}), 500


@app.route("/api/phases/phaseB01_review/approve/<case_id>", methods=["POST"])
def approve_deliverables_endpoint(case_id):
    """
    Approve Phase A03 deliverables and unlock Phase B02 drafting
    Records approval state and validates before allowing transition
    """
    try:
        data = request.get_json() or {}
        approvals = data.get("approvals", {})
        
        logger.info(f"Approving deliverables for case {case_id}: {approvals}")
        
        # Validate first
        validation_result = handle_review_phase(case_id, {})
        
        if not validation_result.get("all_valid", False):
            return jsonify({
                "success": False,
                "message": "Cannot approve - validation failed",
                "validations": validation_result.get("validations", {}),
                "ready_for_drafting": False
            }), 400
        
        # Check that all deliverables are approved
        required_approvals = ["shotlist", "claimsMatrix", "skeletalOutline"]
        all_approved = all(approvals.get(key, False) for key in required_approvals)
        
        if not all_approved:
            return jsonify({
                "success": False,
                "message": "All deliverables must be approved",
                "approvals": approvals,
                "ready_for_drafting": False
            }), 400
        
        # Store approval state
        approval_dir = Path(f"./workflow_storage/cases/{case_id}")
        approval_dir.mkdir(parents=True, exist_ok=True)
        approval_path = approval_dir / "deliverable_approvals.json"
        
        approval_data = {
            "case_id": case_id,
            "approvals": approvals,
            "approved_at": time.time(),
            "approved_by": "user",  # TODO: Add actual user tracking
            "validations_passed": validation_result.get("validations", {})
        }
        
        with open(approval_path, 'w') as f:
            json.dump(approval_data, f, indent=2)
        
        logger.info(f"Deliverables approved for case {case_id}")
        
        # Emit Socket.IO event
        socketio.emit("deliverables_approved", {
            "case_id": case_id,
            "timestamp": time.time(),
            "ready_for_drafting": True
        })
        
        return jsonify({
            "success": True,
            "message": "All deliverables approved - Phase B02 unlocked",
            "approvals": approvals,
            "ready_for_drafting": True,
            "approval_path": str(approval_path)
        })
        
    except Exception as e:
        logger.error(f"Approval failed for case {case_id}: {e}")
        return jsonify({"error": str(e), "success": False}), 500


@app.route("/api/deliverables/<case_id>/<deliverable_type>", methods=["GET"])
def download_deliverable(case_id, deliverable_type):
    """
    Download Phase A03 deliverables as files
    Supported types: shotlist.csv, claims_matrix.json, skeletal_outline.json
    """
    try:
        from flask import send_file
        
        deliverable_dir = Path(f"./workflow_storage/cases/{case_id}/deliverables")
        
        # Map deliverable types to filenames
        file_map = {
            "shotlist.csv": "shotlist.csv",
            "claims_matrix.json": "claims_matrix.json",
            "skeletal_outline.json": "skeletal_outline.json"
        }
        
        if deliverable_type not in file_map:
            return jsonify({"error": f"Unknown deliverable type: {deliverable_type}"}), 400
        
        file_path = deliverable_dir / file_map[deliverable_type]
        
        if not file_path.exists():
            return jsonify({
                "error": f"Deliverable not found: {deliverable_type}",
                "case_id": case_id,
                "expected_path": str(file_path)
            }), 404
        
        # Determine MIME type
        mime_type = "text/csv" if deliverable_type.endswith(".csv") else "application/json"
        
        return send_file(
            file_path,
            mimetype=mime_type,
            as_attachment=True,
            download_name=f"{case_id}_{deliverable_type}"
        )
        
    except Exception as e:
        logger.error(f"Failed to download deliverable {deliverable_type} for case {case_id}: {e}")
        return jsonify({"error": str(e)}), 500


# ============================================================================
# LLM CONFIGURATION API ENDPOINTS
# ============================================================================

@app.route("/api/settings/llm", methods=["GET"])
def get_llm_config():
    """Get current LLM configuration (without exposing API key)"""
    try:
        safe_config = llm_config.copy()
        # Mask API key
        if safe_config.get("api_key"):
            safe_config["api_key"] = "***" + safe_config["api_key"][-4:] if len(safe_config["api_key"]) > 4 else "***"
        
        return jsonify({
            "success": True,
            "config": safe_config,
            "available_providers": ["openai", "anthropic", "groq", "gemini"],
            "available_models": {
                "openai": ["gpt-4", "gpt-4-turbo", "gpt-3.5-turbo"],
                "anthropic": ["claude-3-opus", "claude-3-sonnet", "claude-3-haiku"],
                "groq": ["mixtral-8x7b", "llama-2-70b"],
                "gemini": ["gemini-pro", "gemini-pro-vision"]
            }
        })
    except Exception as e:
        logger.error(f"Failed to get LLM config: {e}")
        return jsonify({"error": str(e)}), 500


@app.route("/api/settings/llm", methods=["POST"])
def update_llm_config():
    """Update LLM configuration"""
    try:
        data = request.get_json()
        
        # Update configuration
        if "provider" in data:
            llm_config["provider"] = data["provider"]
        if "model" in data:
            llm_config["model"] = data["model"]
        if "api_key" in data and data["api_key"] != "":
            llm_config["api_key"] = data["api_key"]
        if "temperature" in data:
            llm_config["temperature"] = float(data["temperature"])
        if "max_tokens" in data:
            llm_config["max_tokens"] = int(data["max_tokens"])
        
        logger.info(f"LLM config updated: {llm_config['provider']}/{llm_config['model']}")
        
        return jsonify({
            "success": True,
            "message": "LLM configuration updated successfully",
            "config": {
                "provider": llm_config["provider"],
                "model": llm_config["model"],
                "temperature": llm_config["temperature"],
                "max_tokens": llm_config["max_tokens"]
            }
        })
    except Exception as e:
        logger.error(f"Failed to update LLM config: {e}")
        return jsonify({"error": str(e)}), 500


# ============================================================================
# DRAFTING VALIDATION API ENDPOINTS
# ============================================================================

@app.route("/api/drafting/validate", methods=["POST"])
def validate_draft_complaint():
    """Validate draft complaint against defendant cluster using LLM-enhanced analysis"""
    if not drafting_validator:
        return jsonify({"error": "Drafting validator not available"}), 503
    
    try:
        data = request.get_json()
        draft_text = data.get("draft_text", "")
        case_id = data.get("case_id", "")
        
        if not draft_text or not case_id:
            return jsonify({"error": "Missing draft_text or case_id"}), 400
        
        # Run async validation in event loop
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            validation_result = loop.run_until_complete(
                drafting_validator.validate_draft_complaint(
                    draft_text=draft_text,
                    case_id=case_id
                )
            )
        finally:
            loop.close()
        
        # Convert validation result to dict
        result_dict = {
            "is_valid": validation_result.is_valid,
            "overall_score": validation_result.overall_score,
            "similarity_score": validation_result.similarity_score,
            "similarity_threshold": validation_result.similarity_threshold,
            "issues_found": validation_result.issues_found,
            "recommendations": validation_result.recommendations,
            "missing_elements": validation_result.missing_elements,
            "processing_time": validation_result.processing_time,
            "defendant_name": validation_result.defendant_name,
            "case_id": validation_result.case_id
        }
        
        return jsonify({
            "success": True,
            "validation_result": result_dict
        })
        
    except Exception as e:
        logger.error(f"Draft validation failed: {e}")
        return jsonify({"error": str(e)}), 500


@app.route("/api/intake/process-document", methods=["POST"])
def process_enhanced_intake_document():
    """Enhanced document processing with categorization and clustering"""
    if not intake_processor:
        return jsonify({"error": "Intake processor not available"}), 503
    
    try:
        file = request.files.get("document")
        case_id = request.form.get("case_id", "")
        
        if not file:
            return jsonify({"error": "No document provided"}), 400
        
        # Read document content
        content = file.read().decode("utf-8", errors="ignore")
        
        # Get defendant hint from case data if available
        defendant_hint = None
        if intake_processor and case_id in getattr(intake_processor, "active_cases", {}):
            defendant_hint = intake_processor.active_cases[case_id].get("defendant_name")
        
        # Run async document processing
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            result = loop.run_until_complete(
                intake_processor.process_document(
                    file_path=file.filename,
                    case_id=case_id,
                    additional_context={"defendant_hint": defendant_hint}
                )
            )
        finally:
            loop.close()
        
        return jsonify({
            "success": result.get("success", False),
            "document_id": result.get("document_id"),
            "document_type": result.get("document_type"),
            "authority_level": result.get("authority_level"),
            "cluster_id": result.get("cluster_id"),
            "confidence_score": result.get("confidence_score"),
            "similar_documents": result.get("similar_documents", 0),
            "defendant_recognized": result.get("defendant_recognized", False)
        })
        
    except Exception as e:
        logger.error(f"Enhanced intake processing failed: {e}")
        return jsonify({"error": str(e)}), 500



def main():
    """Main server entry point with proper error handling."""
    parser = argparse.ArgumentParser(description="LawyerFactory Canonical API Server")
    parser.add_argument("--port", type=int, default=5000, help="Port to run server on")
    parser.add_argument("--host", type=str, default="127.0.0.1", help="Host to run server on")
    parser.add_argument("--debug", action="store_true", help="Enable debug mode")
    args = parser.parse_args()

    try:
        print("🚀 Starting LawyerFactory Canonical API Server...")
        
        # Initialize canonical evidence API (registers blueprint)
        print("📊 Initializing Evidence Management System...")
        if initialize_canonical_evidence_api(app, socketio):
            print("✅ Evidence API initialized successfully")
        else:
            print("⚠️  Evidence API initialization failed - some features may be unavailable")
        
        print(f"🌐 Server: http://{args.host}:{args.port}")
        print("📡 SocketIO async mode: eventlet")
        print(f"✅ Health endpoint: http://{args.host}:{args.port}/api/health")
        print(f"📊 Evidence API: http://{args.host}:{args.port}/api/evidence")
        print(f"🔍 Research API: http://{args.host}:{args.port}/api/evidence/research")
        print(f"🎯 Phase Orchestration: http://{args.host}:{args.port}/api/phases/<phase_id>/start")

        # Run with eventlet using the global app and socketio instances
        socketio.run(
            app,
            host=args.host,
            port=args.port,
            debug=args.debug,
            use_reloader=False,  # Disable reloader with eventlet
        )

    except Exception as e:
        print(f"❌ Server startup failed: {e}")
        logging.exception("Server startup error")
        sys.exit(1)


if __name__ == "__main__":
    main()

