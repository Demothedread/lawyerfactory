# Script Name: research.py
# Description: Enhanced Research Bot for automated legal research capabilities. Integrates with CourtListener API, Google Scholar, and other legal databases.
# Relationships:
#   - Entity Type: Module
#   - Directory Group: Research
#   - Group Tags: legal-research
Enhanced Research Bot for automated legal research capabilities.
Integrates with CourtListener API, Google Scholar, and other legal databases.
"""

import asyncio
import hashlib
import json
import logging
import os
import re
import time
import urllib.error
import urllib.parse
import urllib.request
from dataclasses import dataclass
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

from ..agent_registry import AgentCapability, AgentConfig, AgentInterface
from ..bot_interface import Bot
from ..workflow_models import WorkflowTask

logger = logging.getLogger(__name__)

@dataclass
class ResearchQuery:
    """Structured research query with context"""
    query_text: str
    legal_issues: List[str]
    jurisdiction: Optional[str] = None #e.g. 'federal', 'state'
    venue: Optional[str] = None #e.g. scotus, 'ca9', 'cal'
    parties: Optional[List[str]] = None
    date_range: Optional[Tuple[str, str]] = None
    citation_types: Optional[List[str]] = None
    entity_ids: Optional[List[str]] = None
    
    def __post_init__(self):
        if self.parties is None:
            self.parties = []
        if self.citation_types is None:
            self.citation_types = ["case", "statute", "regulation"]
        if self.entity_ids is None:
            self.entity_ids = []


@dataclass
class LegalCitation:
    """Legal citation with metadata"""
    citation: str
    title: str
    court: Optional[str] = None
    year: Optional[int] = None
    jurisdiction: Optional[str] = None
    citation_type: str = "case"  # case, statute, regulation
    url: Optional[str] = None
    relevance_score: float = 0.0
    authority_level: int = 1  # 1=highest (Supreme Court), 5=lowest
    excerpt: Optional[str] = None
    full_text: Optional[str] = None


@dataclass
class ResearchResult:
    """Research result with analysis"""
    query_id: str
    citations: List[LegalCitation]
    legal_principles: List[str]
    gaps_identified: List[str]
    recommendations: List[str]
    confidence_score: float
    search_metadata: Dict[str, Any]
    created_at: datetime


class CourtListenerClient:
    """Client for CourtListener API integration using urllib"""
    
    def __init__(self, api_token: Optional[str] = None):
        self.base_url = "https://www.courtlistener.com/api/rest/v4/"
        self.api_token = api_token or os.environ.get('COURTLISTENER_API_KEY')
        self.rate_limit = {
            'requests_per_minute': 5000 if self.api_token else 100,
            'last_request': 0,
            'request_count': 0,
            'reset_time': time.time() + 60
        }
    
    async def _rate_limit_check(self):
        """Enforce API rate limits"""
        current_time = time.time()
        
        if current_time > self.rate_limit['reset_time']:
            self.rate_limit['request_count'] = 0
            self.rate_limit['reset_time'] = current_time + 60
        
        if self.rate_limit['request_count'] >= self.rate_limit['requests_per_minute']:
            sleep_time = self.rate_limit['reset_time'] - current_time
            logger.info(f"Rate limit reached, sleeping for {sleep_time:.2f} seconds")
            await asyncio.sleep(sleep_time)
            self.rate_limit['request_count'] = 0
            self.rate_limit['reset_time'] = time.time() + 60
        
        self.rate_limit['request_count'] += 1
        self.rate_limit['last_request'] = current_time
    
    async def search_opinions(self, query: str, jurisdiction: Optional[str] = None, 
                            court: Optional[str] = None, limit: int = 20) -> List[Dict]:
        """Search for court opinions"""
        await self._rate_limit_check()
        
        params = {
            'q': query,
            'type': 'o',  # opinions
            'order_by': 'score desc',
            'format': 'json'
        }
        
        if jurisdiction:
            params['jurisdiction'] = jurisdiction
            #v4 expects 'FD' for federal or state slugs
        if court:
            params['court'] = court
        if limit:
            params['page_size4'] = str(min(limit, 100))  # API max, convert to string
        
        try:
            url = f"{self.base_url}search/?" + urllib.parse.urlencode(params)
            headers = {}
            if self.api_token:
                headers['Authorization'] = f'Token {self.api_token}'
            
            request = urllib.request.Request(url, headers=headers)
            
            # Run in thread pool to avoid blocking
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(None, urllib.request.urlopen, request)
            
            data = json.loads(response.read().decode('utf-8'))
            return data.get('results', [])
            
        except Exception as e:
            logger.error(f"CourtListener search failed: {e}")
            return self._mock_opinion_results(query, limit)
    
    def _mock_opinion_results(self, query: str, limit: int) -> List[Dict]:
        """Mock results when API is not available"""
        return [
            {
                'case_name': f'Mock Case {i+1} for {query}',
                'citation': {'neutral_cite': f'Mock Cite {i+1} (2023)'},
                'court': {'short_name': 'Mock Court', 'jurisdiction': 'US'},
                'date_filed_year': 2023,
                'absolute_url': f'https://mock.court/{i}',
                'snippet': f'This is a mock case result {i+1} for query: {query}. '
                          f'The court held that relevant legal principles apply in cases involving {query.lower()}.'
            } for i in range(min(limit, 5))
        ]
    
    async def get_opinion_details(self, opinion_id: str) -> Dict:
        """Get detailed opinion information"""
        await self._rate_limit_check()
        
        try:
            url = f"{self.base_url}opinions/{opinion_id}/"
            headers = {}
            if self.api_token:
                headers['Authorization'] = f'Token {self.api_token}'
            
            request = urllib.request.Request(url, headers=headers)
            
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(None, urllib.request.urlopen, request)
            
            return json.loads(response.read().decode('utf-8'))
            
        except Exception as e:
            logger.error(f"Failed to get opinion details: {e}")
            return {'mock': True, 'opinion_id': opinion_id}

    async def get_opinion_cluster(self, cluster_id: str) -> Dict:
        """Fetch opinion-cluster (to enumerate sub-opinions like concurrences/dissents)"""
        await self._rate_limit_check()
        try:
            url = f"{self.base_url}opinion-clusters/{cluster_id}/"
            headers = {'Authorization': f'Token {self.api_token}'} if self.api_token else {}
            req = urllib.request.Request(url, headers=headers)
            loop = asyncio.get_event_loop()
            resp = await loop.run_in_executor(None, urllib.request.urlopen, req)
            return json.loads(resp.read().decode('utf-8'))
        except Exception as e:
            logger.error(f"Failed to get opinion cluster: {e}")
            return {'mock': True, 'cluster_id': cluster_id}

    async def get_best_opinion_text(self, opinion_id: Optional[str] = None, cluster_id: Optional[str] = None) -> Dict:
        """
        Retrieve the best available text for an opinion or cluster.
        Preference: html_with_citations -> html -> plain_text.
        Returns: {'text': str, 'format': str, 'opinion_ids': [..]}
        """
        try:
            texts = []
            ids = []
            if cluster_id:
                cluster = await self.get_opinion_cluster(str(cluster_id))
                sub_ops = cluster.get('sub_opinions') or []
                for sub in sub_ops:
                    sid = str(sub.get('id') or '')
                    if sid:
                        ids.append(sid)
                        detail = await self.get_opinion_details(sid)
                        texts.append(detail)
            if opinion_id:
                detail = await self.get_opinion_details(str(opinion_id))
                ids.append(str(opinion_id))
                texts.append(detail)

            # Pick best field available across any gathered opinions
            def pick(d):
                for k in ('html_with_citations', 'html', 'plain_text'):
                    v = d.get(k)
                    if v and isinstance(v, str) and len(v.strip()) > 0:
                        return (k, v)
                return (None, None)

            # Prefer the first with html_with_citations
            for d in texts:
                k, v = pick(d)
                if k == 'html_with_citations':
                    return {'text': v, 'format': k, 'opinion_ids': ids}
            # Then any html/plain_text
            for d in texts:
                k, v = pick(d)
                if k:
                    return {'text': v, 'format': k, 'opinion_ids': ids}

            return {'text': '', 'format': 'none', 'opinion_ids': ids}
        except Exception as e:
            logger.error(f"get_best_opinion_text failed: {e}")
            return {'text': '', 'format': 'error', 'opinion_ids': []}
class OpenAlexClient:
    """Minimal OpenAlex client for academic law/secondary sources (no API key required)."""

    def __init__(self, contact_email: Optional[str] = None):
        self.base_url = "https://api.openalex.org/works"
        self.contact_email = contact_email or "mailto:researchbot@example.com"

    async def search_legal(self, query: str, limit: int = 10) -> List[Dict]:
        """
        Search OpenAlex for relevant works. Filters to journal articles where possible.
        """
        params = {
            "search": query,
            "per_page": str(min(limit, 25))
        }
        # You can add filters like: primary_location.source.type:journal, from_publication_date:2010-01-01
        url = f"{self.base_url}?" + urllib.parse.urlencode(params)
        headers = {"User-Agent": f"lawyerfactory/1.0 ({self.contact_email})"}
        try:
            loop = asyncio.get_event_loop()
            req = urllib.request.Request(url, headers=headers)
            resp = await loop.run_in_executor(None, urllib.request.urlopen, req)
            data = json.loads(resp.read().decode("utf-8"))
            results = data.get('results') or data.get('data') or []
            out = []
            for r in results[:limit]:
                title = r.get('title') or ''
                year = (
                    r.get('publication_year')
                    or (r.get('from_publication_date') or '')[:4]
                    or None
                )
                url_pdf = None
                # Try to find an open-access url
                oa = r.get('open_access', {}) if isinstance(r.get('open_access'), dict) else {}
                url_pdf = oa.get('oa_url') or oa.get('any_repository_has_fulltext') or None
                out.append({
                    'title': title,
                    'year': int(year) if year and str(year).isdigit() else None,
                    'citation': r.get('id') or '',
                    'url': url_pdf or r.get('primary_location', {}).get('source', {}).get('host_organization_name') or '',
                    'snippet': (
                        ' '.join(list(r.get('abstract_inverted_index', {}).keys()))
                        if r.get('abstract_inverted_index') else ''
                    )
                })
            return out
        except Exception as e:
            logger.error(f"OpenAlex search failed: {e}")
            return []
        
class GoogleScholarClient:
    """Client for Google Scholar legal research (with rate limiting)"""
    
    def __init__(self):
        self.base_url = "https://scholar.google.com/scholar"
        self.rate_limit = {
            'requests_per_minute': 20,  # Conservative rate limiting
            'last_request': 0,
            'request_count': 0,
            'reset_time': time.time() + 60
        }
    
    async def _rate_limit_check(self):
        """Conservative rate limiting for Google Scholar"""
        current_time = time.time()
        
        if current_time > self.rate_limit['reset_time']:
            self.rate_limit['request_count'] = 0
            self.rate_limit['reset_time'] = current_time + 60
        
        if self.rate_limit['request_count'] >= self.rate_limit['requests_per_minute']:
            sleep_time = self.rate_limit['reset_time'] - current_time + 5  # Extra buffer
            logger.info(f"Google Scholar rate limit, sleeping for {sleep_time:.2f} seconds")
            await asyncio.sleep(sleep_time)
            self.rate_limit['request_count'] = 0
            self.rate_limit['reset_time'] = time.time() + 60
        
        self.rate_limit['request_count'] += 1
        # Add delay between requests
        if self.rate_limit['last_request'] > 0:
            time_since_last = current_time - self.rate_limit['last_request']
            if time_since_last < 3:  # Minimum 3 seconds between requests
                await asyncio.sleep(3 - time_since_last)
        
        self.rate_limit['last_request'] = time.time()
    
    async def search_legal(self, query: str, limit: int = 10) -> List[Dict]:
        """Search Google Scholar for legal documents"""
        await self._rate_limit_check()
        
        # For this implementation, we'll return mock results to avoid complex HTML parsing
        # In production, you would use a proper web scraping library
        return self._mock_scholar_results(query, limit)
    
    def _mock_scholar_results(self, query: str, limit: int) -> List[Dict]:
        """Mock results for testing - replace with actual parsing in production"""
        return [
            {
                'title': f'Legal Analysis of {query} - Article {i+1}',
                'authors': [f'Scholar Author {i+1}'],
                'year': 2023 - (i % 3),
                'citation': f'Legal Review Analysis of {query} Vol. {i+1} (2023)',
                'url': f'https://scholar.google.com/mock/{i}',
                'snippet': f'This scholarly analysis covers key aspects of {query} in current legal framework. '
                          f'The article examines precedents and discusses implications for practice.'
            } for i in range(min(limit, 5))
        ]


class ResearchBot(Bot, AgentInterface):
    """Enhanced research bot for comprehensive legal research"""
    
    def __init__(self, knowledge_graph, courtlistener_token: Optional[str] = None):
        # Initialize Bot interface
        Bot.__init__(self)
        # Initialize AgentInterface
        config = AgentConfig(
            agent_type="ResearchBot",
            capabilities=[AgentCapability.LEGAL_RESEARCH],
            max_concurrent=2,
            timeout_seconds=1800,  # 30 minutes for research tasks
            retry_attempts=3
        )
        AgentInterface.__init__(self, config)
        
        self.knowledge_graph = knowledge_graph
        self.courtlistener_token = courtlistener_token
        self.result_cache = {}
        self.authority_hierarchy = {
            'supreme court': 1,
            'court of appeals': 2, 
            'appellate court': 2,
            'district court': 3,
            'trial court': 4,
            'other': 5
        }
        
        logger.info("ResearchBot initialized with legal research capabilities")
    
    async def process(self, message: str) -> str:
        """Legacy Bot interface implementation"""
        query = message  # Rename for clarity
        research_query = ResearchQuery(
            query_text=query,
            legal_issues=[query]
        )
        
        result = await self.execute_research(research_query)
        return self._format_research_summary(result)
    
    async def execute_task(self, task: WorkflowTask, context: Dict[str, Any]) -> Dict[str, Any]:
        """AgentInterface implementation for orchestration system"""
        logger.info(f"ResearchBot executing task: {task.id}")
        
        try:
            # Extract research parameters from task context
            research_query = await self._build_research_query_from_context(task, context)
            
            # Execute comprehensive research
            research_result = await self.execute_research(research_query)
            
            # Store results in knowledge graph
            await self._store_research_results(research_result, task.id)
            
            # Perform gap analysis
            gaps = await self._analyze_research_gaps(research_result, context)
            
            return {
                'status': 'completed',
                'result_type': 'research_analysis',
                'citations_found': len(research_result.citations),
                'legal_principles': research_result.legal_principles,
                'gaps_identified': gaps,
                'recommendations': research_result.recommendations,
                'confidence_score': research_result.confidence_score,
                'research_id': research_result.query_id
            }
            
        except Exception as e:
            logger.error(f"Research task failed: {e}")
            return {
                'status': 'failed',
                'error': str(e),
                'recommendations': ['Retry with simplified query', 'Check API connectivity']
            }
    
    async def health_check(self) -> bool:
        """Check if research APIs are accessible"""
        try:
            # Test basic connectivity
            cl_client = CourtListenerClient(self.courtlistener_token)
            await cl_client._rate_limit_check()
            
            gs_client = GoogleScholarClient()
            await gs_client._rate_limit_check()

            alex_client = OpenAlexClient()
            await alex_client._rate_limit_check()

            return True
        except Exception as e:
            logger.error(f"Research bot health check failed: {e}")
            return False
    
    async def initialize(self) -> None:
        """Initialize research resources and validate APIs"""
        logger.info("Initializing ResearchBot resources...")
        
        # Test API connections
        if not await self.health_check():
            logger.warning("Some research APIs may not be accessible")
        
        logger.info("ResearchBot initialization complete")
    
    async def cleanup(self) -> None:
        """Clean up research resources"""
        # Clear cache
        self.result_cache.clear()
        logger.info("ResearchBot cleanup complete")
    
    async def execute_research(self, query: ResearchQuery) -> ResearchResult:
        """Execute comprehensive legal research"""
        query_id = self._generate_query_id(query)
        
        # Check cache first
        if query_id in self.result_cache:
            logger.info(f"Returning cached research result for {query_id}")
            return self.result_cache[query_id]
        
        logger.info(f"Executing research for query: {query.query_text}")
        
        all_citations = []
        search_metadata = {
            'sources': [],
            'queries_executed': [],
            'start_time': datetime.now(),
            'api_calls': 0
        }
        
        # Search CourtListener for case law
        try:
            cl_citations = await self._search_courtlistener(query)
            all_citations.extend(cl_citations)
            search_metadata['sources'].append('courtlistener')
            search_metadata['api_calls'] += len(cl_citations)
        except Exception as e:
            logger.error(f"CourtListener search failed: {e}")
        
        # Search Google Scholar for academic sources
        try:
            gs_citations = await self._search_google_scholar(query)
            all_citations.extend(gs_citations)
            search_metadata['sources'].append('google_scholar')
            search_metadata['api_calls'] += len(gs_citations)
        except Exception as e:
            logger.error(f"Google Scholar search failed: {e}")
        
        try:
            acad_citations = await self._search_academic(query)
            all_citations.extend(acad_citations)
            search_metadata['sources'].append('openalex')
            search_metadata['api_calls'] += len(acad_citations)
        except Exception as e:
            logger.error(f"Academic (OpenAlex) search failed: {e}")

        # Score and rank citations
        scored_citations = await self._score_citations(all_citations, query)
        
        # Extract legal principles
        legal_principles = await self._extract_legal_principles(scored_citations)
        
        # Identify research gaps
        gaps = await self._identify_research_gaps(query, scored_citations)
        
        # Generate recommendations
        recommendations = await self._generate_recommendations(query, scored_citations, gaps)
        
        # Calculate overall confidence
        confidence_score = self._calculate_confidence_score(scored_citations, gaps)
        
        search_metadata['end_time'] = datetime.now()
        search_metadata['duration'] = (search_metadata['end_time'] - search_metadata['start_time']).total_seconds()
        
        result = ResearchResult(
            query_id=query_id,
            citations=scored_citations[:50],  # Limit to top 50 results
            legal_principles=legal_principles,
            gaps_identified=gaps,
            recommendations=recommendations,
            confidence_score=confidence_score,
            search_metadata=search_metadata,
            created_at=datetime.now()
        )
        
        # Cache result
        self.result_cache[query_id] = result
        
        logger.info(f"Research completed: {len(scored_citations)} citations found, confidence: {confidence_score:.2f}")
        
        return result
    
    async def _build_research_query_from_context(self, task: WorkflowTask, context: Dict[str, Any]) -> ResearchQuery:
        """Build research query from task context, including intake data"""
        # Extract intake data if available
        intake_data = context.get("intake_data", {})
        jurisdiction = intake_data.get("jurisdiction", context.get("jurisdiction"))
        venue = intake_data.get("venue", context.get("venue"))
        causes_of_action = intake_data.get("causes_of_action", [])
        claim_description = intake_data.get("claim_description", "")

        # Build legal issues from causes of action and claim description
        legal_issues = causes_of_action.copy() if causes_of_action else []
        if claim_description:
            # Extract key legal terms from claim description
            legal_terms = self._extract_legal_terms(claim_description)
            legal_issues.extend(legal_terms)

        # Build query text from task description and intake data
        query_parts = []
        if task.description:
            query_parts.append(task.description)
        if claim_description:
            query_parts.append(claim_description)
        if causes_of_action:
            query_parts.append(" ".join(causes_of_action))

        query_text = " ".join(query_parts)

        # Extract parties from intake data
        parties = []
        if intake_data.get("client_name"):
            parties.append(intake_data["client_name"])
        if intake_data.get("opposing_party_names"):
            parties.extend(intake_data["opposing_party_names"].split(","))

        return ResearchQuery(
            query_text=query_text,
            legal_issues=legal_issues,
            jurisdiction=jurisdiction,
            venue=venue,
            parties=parties,
            date_range=None,  # Could be extracted from events_date
            citation_types=["case", "statute", "regulation"]
        )

    def _extract_legal_terms(self, text: str) -> List[str]:
        """Extract legal terms from text for research"""
        # Common legal terms to look for
        legal_terms = [
            "negligence", "breach", "contract", "tort", "liability",
            "damages", "injury", "violation", "wrongful", "defamation",
            "fraud", "misrepresentation", "discrimination", "harassment"
        ]

        found_terms = []
        text_lower = text.lower()

        for term in legal_terms:
            if term in text_lower:
                found_terms.append(term)

        return found_terms
    async def _build_research_query_from_context(self, task: WorkflowTask, context: Dict[str, Any]) -> ResearchQuery:
        """Build research query from workflow task context and knowledge graph"""
        # Extract entities from knowledge graph
        case_entities = []
        legal_issues = []
        parties = []
        jurisdiction = None
        
        # Query knowledge graph for relevant entities
        case_facts = None
        if 'case_id' in context:
            case_facts = self.knowledge_graph.get_case_facts(context['case_id'])
            
            if case_facts:
                for entity in case_facts.get('entities', []):
                    if entity.get('type') == 'PERSON':
                        parties.append(entity['name'])
                    elif entity.get('type') == 'ORG':
                        parties.append(entity['name'])
                    elif entity.get('type') == 'LEGAL_ISSUE':
                        legal_issues.append(entity['name'])
                    elif entity.get('type') == 'JURISDICTION':
                        jurisdiction = entity['name']
        
        # Build query text from task description and entities
        query_components = [task.description]
        if legal_issues:
            query_components.extend(legal_issues)
        
        query_text = ' '.join(query_components)
        
        entity_ids = []
        if case_facts:
            entity_ids = [e.get('id') for e in case_facts.get('entities', []) if e.get('id')]
        
        return ResearchQuery(
            query_text=query_text,
            legal_issues=legal_issues or [task.description],
            jurisdiction=jurisdiction,
            parties=parties,
            entity_ids=entity_ids
        )
    
    async def _search_courtlistener(self, query: ResearchQuery) -> List[LegalCitation]:
        """Search CourtListener API for case law"""
        citations = []
        
        client = CourtListenerClient(self.courtlistener_token)
        
        # Main query search
        results = await client.search_opinions(
            query=query.query_text,
            jurisdiction=query.jurisdiction,
            court=query.venue,
            limit=20
        )
        
        for result in results:
            citation = self._parse_courtlistener_result(result)
            if citation:
                citations.append(citation)

        # Optionally fetch full text for the top hits
        for c in citations[:7]:
            # Try to extract opinion_id and cluster_id from citation or URL
            opinion_id = getattr(c, 'opinion_id', None)
            cluster_id = getattr(c, "cluster_id", None)
            if not opinion_id and c.url:
                m = re.search(r'/opinion/(\d+)/', c.url)
                if m:
                    opinion_id = m.group(1)
            # Prefer cluster_id if available for richer text (majority/concurrence/dissent)
            try:
                if cluster_id or opinion_id:
                    best = await client.get_best_opinion_text(
                        opinion_id=opinion_id,
                        cluster_id=cluster_id
                    )
                    if best.get('text'):
                        c.full_text = best['text']
            except Exception as e:
                logger.error(f"Failed to fetch full text for citation: {e}")
        
        # Additional searches for specific legal issues
        for legal_issue in query.legal_issues[:3]:  # Limit to avoid excessive API calls
            issue_results = await client.search_opinions(
                query=legal_issue,
                jurisdiction=query.jurisdiction,
                limit=10
            )
            
            for result in issue_results:
                citation = self._parse_courtlistener_result(result)
                if citation and citation not in citations:
                    citations.append(citation)
        
        return citations
    
    def _parse_courtlistener_result(self, result: Dict) -> Optional[LegalCitation]:
        """Parse CourtListener API result into LegalCitation"""
        try:
            citation_data = result.get('citation', {})
            citation_text = (citation_data.get('neutral_cite') or 
                           citation_data.get('federal_cite_one') or 
                           result.get('case_name', 'Unknown Citation'))
            
            court_data = result.get('court', {})
            court_name = court_data.get('short_name', '')
            authority_level = self._determine_authority_level(court_name)
            
            return LegalCitation(
                citation=citation_text,
                title=result.get('case_name', ''),
                court=court_name,
                year=result.get('date_filed_year'),
                jurisdiction=court_data.get('jurisdiction'),
                citation_type='case',
                url=result.get('absolute_url'),
                authority_level=authority_level,
                excerpt=result.get('snippet', '')
            )
        except Exception as e:
            logger.error(f"Failed to parse CourtListener result: {e}")
            return None
    
    async def _search_google_scholar(self, query: ResearchQuery) -> List[LegalCitation]:
        """Search Google Scholar for academic legal sources"""
        citations = []
        
        client = GoogleScholarClient()
        
        # Search for main query
        results = await client.search_legal(query.query_text, limit=10)
        
        for result in results:
            citation = self._parse_scholar_result(result)
            if citation:
                citations.append(citation)
        
        return citations
    
    def _parse_scholar_result(self, result: Dict) -> Optional[LegalCitation]:
        """Parse Google Scholar result into LegalCitation"""
        try:
            return LegalCitation(
                citation=result.get('citation', ''),
                title=result.get('title', ''),
                year=result.get('year'),
                citation_type='academic',
                url=result.get('url'),
                authority_level=3,  # Academic sources get medium authority
                excerpt=result.get('snippet', '')
            )
        except Exception as e:
            logger.error(f"Failed to parse Scholar result: {e}")
            return None
    async def _search_academic(self, query: ResearchQuery) -> List[LegalCitation]:
        """Search academic/secondary sources via OpenAlex."""
        citations = []
        client = OpenAlexClient()
        try:
            results = await client.search_legal(query.query_text, limit=10)
            for r in results:
                try:
                    citations.append(
                        LegalCitation(
                            citation=r.get('citation', ''),
                            title=r.get('title', ''),
                            year=r.get('year'),
                            citation_type='academic',
                            url=r.get('url'),
                            authority_level=3,
                            excerpt=r.get('snippet', '')
                        )
                    )
                except Exception as e:
                    logger.error(f"Failed to parse OpenAlex result: {e}")
        except Exception as e:
            logger.error(f"OpenAlex search failed: {e}")
        return citations
    def _determine_authority_level(self, court_name: str) -> int:
        """Determine authority level based on court name"""
        court_lower = court_name.lower()
        
        for court_type, level in self.authority_hierarchy.items():
            if court_type in court_lower:
                return level
        
        return 5  # Default to lowest authority
    
    async def _score_citations(self, citations: List[LegalCitation], query: ResearchQuery) -> List[LegalCitation]:
        """Score and rank citations by relevance and authority"""
        scored_citations = []
        
        for citation in citations:
            relevance_score = self._calculate_relevance_score(citation, query)
            authority_score = self._calculate_authority_score(citation)
            
            # Combined score: 70% relevance, 30% authority
            citation.relevance_score = (0.7 * relevance_score) + (0.3 * authority_score)
            scored_citations.append(citation)
        
        # Sort by score (descending) and remove duplicates
        scored_citations.sort(key=lambda x: x.relevance_score, reverse=True)
        return self._deduplicate_citations(scored_citations)
    
    def _calculate_relevance_score(self, citation: LegalCitation, query: ResearchQuery) -> float:
        """Calculate relevance score based on text matching"""
        score = 0.0
        
        # Text matching with query
        text_to_search = f"{citation.title} {citation.excerpt or ''}".lower()
        query_terms = query.query_text.lower().split()
        
        matches = sum(1 for term in query_terms if term in text_to_search)
        score += (matches / len(query_terms)) * 0.5
        
        # Legal issue matching
        for issue in query.legal_issues:
            if issue.lower() in text_to_search:
                score += 0.2
        
        # Jurisdiction matching
        if query.jurisdiction and citation.jurisdiction:
            if query.jurisdiction.lower() in citation.jurisdiction.lower():
                score += 0.2
        
        # Recency bonus (within last 10 years)
        if citation.year and citation.year >= (datetime.now().year - 10):
            score += 0.1
        
        return min(score, 1.0)
    
    def _calculate_authority_score(self, citation: LegalCitation) -> float:
        """Calculate authority score based on court hierarchy"""
        # Higher authority level = lower number = higher score
        return 1.0 - ((citation.authority_level - 1) / 4)
    
    def _deduplicate_citations(self, citations: List[LegalCitation]) -> List[LegalCitation]:
        """Remove duplicate citations based on title and citation text"""
        seen = set()
        unique_citations = []
        
        for citation in citations:
            key = f"{citation.title}|{citation.citation}".lower()
            if key not in seen:
                seen.add(key)
                unique_citations.append(citation)
        
        return unique_citations
    
    async def _extract_legal_principles(self, citations: List[LegalCitation]) -> List[str]:
        """Extract key legal principles from top citations"""
        principles = set()
        
        # Analyze top 10 citations for common principles
        for citation in citations[:10]:
            if citation.excerpt:
                # Simple keyword extraction - in production would use NLP
                text = citation.excerpt.lower()
                
                # Common legal principle patterns
                principle_patterns = [
                    r'holding that (.+?)[\.\,]',
                    r'established that (.+?)[\.\,]',
                    r'rule that (.+?)[\.\,]',
                    r'doctrine of (.+?)[\.\,]',
                    r'principle of (.+?)[\.\,]'
                ]
                
                for pattern in principle_patterns:
                    matches = re.findall(pattern, text)
                    for match in matches:
                        if len(match.strip()) > 10:  # Filter short matches
                            principles.add(match.strip())
        
        return list(principles)[:10]  # Return top 10 principles
    
    async def _identify_research_gaps(self, query: ResearchQuery, citations: List[LegalCitation]) -> List[str]:
        """Identify gaps in research coverage"""
        gaps = []
        
        # Check jurisdiction coverage
        jurisdictions_found = set()
        for citation in citations:
            if citation.jurisdiction:
                jurisdictions_found.add(citation.jurisdiction)
        
        if query.jurisdiction and query.jurisdiction not in jurisdictions_found:
            gaps.append(f"Limited coverage for jurisdiction: {query.jurisdiction}")
        
        # Check recency of citations
        recent_citations = [c for c in citations if c.year and c.year >= (datetime.now().year - 5)]
        if len(recent_citations) < 3:
            gaps.append("Limited recent case law found")
        
        # Check authority levels
        high_authority = [c for c in citations if c.authority_level <= 2]
        if len(high_authority) < 2:
            gaps.append("Limited high-authority precedents found")
        
        # Check legal issue coverage
        for issue in query.legal_issues:
            issue_coverage = sum(1 for c in citations if issue.lower() in (c.excerpt or '').lower())
            if issue_coverage < 2:
                gaps.append(f"Limited coverage for legal issue: {issue}")
        
        return gaps
    
    async def _generate_recommendations(self, query: ResearchQuery, citations: List[LegalCitation], gaps: List[str]) -> List[str]:
        """Generate research recommendations based on findings and gaps"""
        recommendations = []
        
        # Address identified gaps
        for gap in gaps:
            if "jurisdiction" in gap:
                recommendations.append(f"Expand search to related jurisdictions for {query.jurisdiction}")
            elif "recent case law" in gap:
                recommendations.append("Search for recent developments and pending legislation")
            elif "high-authority" in gap:
                recommendations.append("Focus search on Supreme Court and appellate court decisions")
            elif "legal issue" in gap:
                issue = gap.split(": ")[-1]
                recommendations.append(f"Conduct specialized research on {issue}")
        
        # Suggest additional research areas
        if len(citations) < 10:
            recommendations.append("Broaden search terms to capture more relevant authorities")
        
        if query.parties:
            recommendations.append("Research specific parties' litigation history")
        
        # Suggest follow-up research
        top_citations = citations[:5]
        if top_citations:
            recommendations.append("Review cited authorities within top results for additional precedents")
        
        return recommendations[:8]  # Limit recommendations
    
    def _calculate_confidence_score(self, citations: List[LegalCitation], gaps: List[str]) -> float:
        """Calculate overall confidence score for research results"""
        base_score = 0.5
        
        # Increase confidence based on citation quality
        if citations:
            avg_relevance = sum(c.relevance_score for c in citations) / len(citations)
            base_score += avg_relevance * 0.3
            
            # High authority citations boost confidence
            high_authority_count = sum(1 for c in citations if c.authority_level <= 2)
            if high_authority_count > 0:
                base_score += min(high_authority_count * 0.1, 0.2)
        
        # Decrease confidence based on gaps
        gap_penalty = len(gaps) * 0.05
        base_score -= gap_penalty
        
        return max(0.0, min(1.0, base_score))
    
    async def _store_research_results(self, result: ResearchResult, task_id: str) -> None:
        """Store research results in knowledge graph"""
        try:
            # Store each citation as an entity
            for citation in result.citations[:20]:  # Store top 20
                entity_data = {
                    'type': 'LEGAL_CITATION',
                    'name': citation.citation,
                    'description': citation.title,
                    'legal_attributes': json.dumps({
                        'court': citation.court,
                        'year': citation.year,
                        'jurisdiction': citation.jurisdiction,
                        'citation_type': citation.citation_type,
                        'authority_level': citation.authority_level,
                        'relevance_score': citation.relevance_score
                    }),
                    'source_text': citation.excerpt,
                    'confidence': citation.relevance_score,
                    'extraction_method': 'research_bot',
                    'verified': True
                }
                
                # Add entity to knowledge graph (would need to implement add_entity method)
                # self.knowledge_graph.add_entity(entity_data)
            
            logger.info(f"Stored {len(result.citations)} research results for task {task_id}")
            
        except Exception as e:
            logger.error(f"Failed to store research results: {e}")
    
    async def _analyze_research_gaps(self, result: ResearchResult, context: Dict[str, Any]) -> List[str]:
        """Analyze gaps in research based on case context"""
        gaps = result.gaps_identified.copy()
        
        # Additional gap analysis based on case context
        if 'case_type' in context:
            case_type = context['case_type']
            relevant_citations = [c for c in result.citations if case_type.lower() in (c.excerpt or '').lower()]
            if len(relevant_citations) < 3:
                gaps.append(f"Limited precedents for {case_type} cases")
        
        return gaps
    
    def _generate_query_id(self, query: ResearchQuery) -> str:
        """Generate unique ID for research query"""
        query_string = f"{query.query_text}|{query.jurisdiction}|{','.join(query.legal_issues)}"
        return hashlib.md5(query_string.encode()).hexdigest()[:12]
    
    def _format_research_summary(self, result: ResearchResult) -> str:
        """Format research result as summary string"""
        summary = f"Research Summary (Confidence: {result.confidence_score:.2f})\n"
        summary += f"Found {len(result.citations)} relevant citations\n\n"
        
        if result.legal_principles:
            summary += "Key Legal Principles:\n"
            for principle in result.legal_principles[:5]:
                summary += f"• {principle}\n"
            summary += "\n"
        
        if result.citations:
            summary += "Top Citations:\n"
            for citation in result.citations[:5]:
                summary += f"• {citation.citation} (Score: {citation.relevance_score:.2f})\n"
            summary += "\n"
        
        if result.gaps_identified:
            summary += "Research Gaps Identified:\n"
            for gap in result.gaps_identified:
                summary += f"• {gap}\n"
            summary += "\n"
        
        if result.recommendations:
            summary += "Recommendations:\n"
            for rec in result.recommendations:
                summary += f"• {rec}\n"
        
        return summary
